%\thispagestyle{fancy}
\chapter{Segmentação de Cenas em Vídeo Digital}
\label{chap:trabalhos_relacionados}

\section{Considerações Iniciais}
\label{sec:consideracoes_iniciais3}

Inúmeras técnicas e algoritmos vêm sendo desenvolvidos para facilitar o acesso e recuperação de conteúdo multimídia ao longo das últimas décadas. Áreas como visualização computacional, processamento digital de imagens, reconhecimento de padrões, hipermídia~\footnote{Hipermídia é a área responsável por desenvolver aplicações que usam relacionamentos associativos entre informações contidas em dados de múltiplas mídias, visando facilitar acesso e manipulação de informações encapsuladas nos dados \cite{Lowe1999}.}, processamento de linguagem natural, entre outras, demandam grandes esforços para diminuir a lacuna entre a capacidade de interpretação humana e o a capacidade de interpretação que os computadores realizam nos dados dos vídeos. 

%Para preencher tal lacuna é necessário que alguma semântica seja empregada nos trabalhos, a fim de extrair segmentos com significado de conteúdo.  Todavia, existe uma etapa anterior que precisa precisa ser realizada, a segmentação em tomadas. Como essa segmentação é um tema abordado exaustivamente na literatura, com resultados expressivos, 

Uma quantidade considerável de características fazem parte das pesquisas que tentam preencher essa lacuna, sendo encontradas em temas relacionados a segmentação de cenas. Essas características fornecidas pelo vídeo permitem diversas classificações baseado em seu conteúdo  e podem ser representadas pelos gêneros de vídeos (esporte, filme, telejornal, documentário, etc.) ou ainda, caso exista, o tipo de tecnologia abordada (\textit{e.g.} padrões MPEG, H.26x, etc). Contudo, a classificação utilizada neste capítulo foi de acordo com as mídias adotadas nos trabalhos, isto é, imagens, áudio, texto ou a combinação de mais de uma delas. A seguir, serão descritos trabalhos usando a classificação mencionada analisando, principalmente, vídeos do gênero telejornais (foco do trabalho), incluindo o estado da arte das técnicas multimodais. É importante enfatizar que os termos \textsf{identificação} e \textsf{segmentação} estão relacionados à identificação da transição de cenas, ou seja, identifica-se em qual momento do vídeo uma cena termina e a outra começa.
%, a qual é um problema de pesquisa mais próximo da área de Personalização e Adaptação de Conteúdo, relatada por \citeonline{Smith2001}.

\section{Características Visuais}
\label{sec:caracvisual}
Dentre as áreas responsáveis pela recuperação por conteúdo, a Recuperação de Conteúdo Baseada em Imagem (do inglês, \textit{Content Based Image Retrieval}-CBIR) é considerada o gargalo na recuperação de conteúdo multimídia \cite{Deb2004}. Isso porque a maior dificuldade está em interpretar o conteúdo das imagens, pois cada pessoa pode interpretá-las de maneiras distintas, ocasionando uma subjetividade que torna difícil o trabalho de extração de informação realizado pelo computador. 

 \citeonline{Zeng2010} identificou aspectos similares nos trabalhos que realizam segmentação de cenas usando características das imagens dos vídeos e classificou-os em três categorias:
 
 \begin{itemize}
 \item Abordagem baseada em agrupamento de tomadas: considera que uma cena é formada por um conjunto de tomadas similares semanticamente, os trabalhos que fazem uso desse método utilizam essa similaridade entre as tomadas para fornecer algum vestígio ou indício de agrupamento \cite{Cao2007, Zhu2009a, Dunlop2010, Zeng2010}. 
 \item Abordagem baseada em detecção de transição: nesta abordagem, transições entre tomadas são consideradas como candidatas a transição de cenas (uma vez que transição de cena é uma transição de tomada, mas nem sempre uma transição de tomada é uma transição de cena) e transições falsas são removidas checando a coerência da semelhança entre tomadas diferentes \cite{Gu2007, Zhu2008, Chen2010, Huang2010}.
 \item Abordagem baseada em modelo: esta abordagem possui a idéia de que para agrupar \textit{N} tomadas em \textit{K} cenas é equivalente a estimar parâmetros de um determinado modelo \cite{Tan2002, Zhai2005, Ren2010}.
 \end{itemize} 

Relacionado ao agrupamento de tomadas, técnicas de textura de CBIR como a Transformada Discreta de Wavelet foi empregada por \citeonline{Zhu2009a} especificamente na etapa de seleção dos quadros-chave. Em conjunto com essa técnica, outra técnica de cor (histograma de variação de nível de cinza) foi usada para que ambas, e em conjunto com variáveis temporais, pudessem agrupar as tomadas do vídeo. A sua principal desvantagem está em detectar mais cenas do que as existentes no vídeo\footnote{evento denominado de \textit{over segmentation}, do inglês.}. Outros trabalhos (Cao2007, Dunlop2010) utilizam classificadores binários baseados em SVM (do inglês, \textit{Support Vector Machine}) para fazer agrupamentos. \citeonline{Cao2007} extrai a cor e a textura dos quadros-chave para esses classificadores, agrupando tomadas de um documentário em cenas usando diferentes classes semânticas. Como resultado foi feito uma comparação com outras técnicas, obtendo melhores resultados, com a ressalva que pode ocorrer resultados errôneos caso haja cenas adjacentes com o mesmo conteúdo semântico. Esses mesmos classificadores também criaram classes semânticas no trabalho de \citeonline{Dunlop2010}, porém rótulos foram adicionados a deterrminados tipos de quadros-chave (tipo externo), descrevendo os componentes da cena de acordo com uma piramide espacial. A pequena quantidade de classes semânticas e a não análise de quadros-chave do tipo interno foram os limitantes desse trabalho. \citeonline{Zeng2010} realizaram o agrupamento de tomadas inserindo autocorrelograma de cor (HSV), distância entre quadros consecutivos e também variáveis temporais em uma matriz de similaridade. Mesmo obtendo um número ínfimo de cenas não detectadas detectou-se muitas cenas erroneamente, com exceção de telejornais, os quais obtiveram bons resultados. 

Como representantes do segundo grupo, \citeonline{Zhu2008} detectaram e removeram os quadros-chave que não possuiam informação útil por intermédio da técnica de comparação com um modelo (do inglês, \textit{template matching}), detectando cenas a partir da similaridade visual e temporal das tomadas que não tiveram seus quadros-chave excluídos. Os níveis de precisão e revocação ficaram acima de 80\% tendo como base de dados um vídeo de entrevistas e quatro filmes de ação. Na mesma linha, \citeonline{Gu2007} elaboraram um procedimento que identifica as transições com um nível mais alto de similaridade, descartando as restantes, com o uso da técnica de Minimização de Energia baseada em Segmentação (do inglês, \textit{Energy Minimization Based Segmentation}), revelando melhores resultados em gêneros de filmes do que em vídeos caseiros. \citeonline{Chen2010} fizeram uso de características de cor e temporais das tomadas para realizar os agrupamentos, fazendo com que as características de intensidade de movimentação das tomadas excluam as transições de cenas redundantes. Um ponto negativo desse trabalho foi a proposta de avaliação, de somente dois filmes, sendo um pequeno segmento de cada um. \citeonline{Huang2010} calcularam a similaridade entre os quadros-chave de tomadas anteriores e posteriores a um determinado quadro-chave, a qual é, por sua vez, uma medida de exclusão ou inclusão para identificar a ocorrência de uma transição cenas. Como a técnica também faz detecção de tomadas, se acontece erro nessa etapa, o erro é replicado na segmentação das cenas. A eficácia de transições de cenas também diminui quando coincide com uma transição gradual de tomadas, pois essa última é um gargalo da técnica. 

Alguns trabalhos utilizam determinados algoritmos que geram modelos a fim de identificar as cenas. \citeonline{Ren2010} geraram um modelo de cena a partir da técnica do modelo de surgimento de superpixels com características de imagens de baixo nível, notadamente em vídeos com cenas urbanas. Como resultado a eficácia de cenas inferidas por esse modelo é melhor do que as nomeadas manualmente em classes semânticas.  A técnica de Cadeia de Markov de Monte Carlo (do inglês, \textit{Markov Chain Monte Carlo}- MCMC) auxilia no processo de modelagem, como acontece com \citeonline{Zhai2005} ao formular a segmentação de cena como um problema de inferência Bayesiana. Mesmo utilizando o MCMC para solucionar o problema, a técnica fica restrita a quantidade de tomadas, pois quanto menor o número, menos eficiente é a técnica. \citeonline{Tan2002} também consideraram o MCMC e aglomera as cenas com o auxílio Modelo de Mistura Gausiana (do inglês, \textit{Gaussian Mixture Model}). Nesse trabalho, cada cena é modelada com uma densidade Gausiana, levando em conta que características visuais similares pertençam a uma mesma cena. Assim, ficou comprovado que essa abordagem consegue descobrir semântica em vídeos de esportes, no entanto, para outros gêneros como vídeos caseiros ou filmes, apenas características de tomadas individuais não são suficientes.  

No gênero de telejornais, a detecção de âncora(s) é uma abordagem muito utilizada para indicar transições de cenas, com a maioria dos trabalhos se baseando no pressuposto que diferentes imagens de âncoras compartilham o mesmo plano de fundo. Trabalhos iniciais, realizados por \citeonline{Zhang1994}, construíram três modelos de âncoras para tomadas de âncora: tomada, quadro e região. A tomada de âncora é modelada como uma sequência de modelos de quadros e um quadro é modelado como um arranjo espacial de regiões. Como resultado, os autores perceberam que os modelos variam de acordo com o canal/transmissora de TV, sendo difícil construir todos os possíveis modelos para todos os diferentes telejornais. Posteriormente, \citeonline{Ma2001} propuseram, um método baseado em detecção de borda para localizar as tomadas dos âncoras, o qual utilizou o operador DoG e generalizou a transformada de Hough (GHT) para equiparar o contorno dos âncoras. A desvantagem dessa abordagem é que consome muito tempo.

Embora histograma de cor seja uma técnica de extração de informação em imagens usada para identificar qualquer tipo de tomada de âncora \cite{Lee2011}, outras pesquisas relatam detecção de âncoras para um tipo específico de padrões de imagens que contenham planos de fundo dinâmico com a figura do âncora. Divididas em duas categorias, plano de fundo dinâmico parcial (Figura \ref{fig:backgrounddinama} e \ref{fig:backgrounddinamb}) e plano de fundo dinâmico global (Figura \ref{fig:backgrounddinamc} e \ref{fig:backgrounddinamd}), \citeonline{Zheng2009} criaram uma técnica para detecção de ambos os casos utilizando um algoritmo que divide as imagens dos âncoras em sub-blocos, calculando seus respectivos histogramas com os histogramas equivalentes dos modelos de imagens de âncoras existentes, afim de identificar similaridades espaciais entre as imagens. Como resultado, o algoritmo mostrou bom desempenho para quaisquer categorias de plano de fundo dinâmico em telejornais japoneses.

\begin{figure*}[!htb]
\centering
\subfigure[]{\includegraphics[scale=0.20]{./img/img_dinam_partial1.jpg}
\label{fig:backgrounddinama}}
\subfigure[]{\includegraphics[scale=0.20]{./img/img_dinam_partial2.jpg}
\label{fig:backgrounddinamb}}\\
\subfigure[]{\includegraphics[scale=0.20]{./img/img_dinam_global2.jpg}
\label{fig:backgrounddinamc}}
\subfigure[]{\includegraphics[scale=0.20]{./img/img_dinam_global1.jpg}
\label{fig:backgrounddinamd}}
\caption{Âncoras com planos de fundo dinâmicos}
\label{fig:backgrounddinam}
\end{figure*}

Outra técnica muito usada para detecção de tomadas de âncoras é o reconhecimento de face \cite{Lan2004, Desanto2006, Danna2007}. Essas abordagens possuem uma boa taxa de detecção, mas não são as melhores escolhas devido à sua inerente complexidade de algoritmos detectores de face. Todavia, há estudos que extraem características de textura com wavelets \cite{Chen2010a} para posterior reconhecimento de face, demonstram melhores resultados na identificação da figura do âncora.

\section{Características de Áudio}

O uso mais comum do áudio para determinar a semântica do vídeo é servir como um auxílio aos métodos que já utilizam outra mídia. A detecção de silêncio, por exemplo, é utilizada em conjunto com técnicas de recuperação baseada em imagens e texto. Em gêneros como filmes, a escolha do áudio torna-se apropriada visto que são geradas muitas ambiguidades visuais na transição de segmentos semânticos com esse gênero \cite{Hanjalic2001}. 

Mas mesmo em conteúdo multimídia, como o vídeo, a segmentação em cenas somente com áudio é possível, apesar da forma de fazê-lo não ser tão intuitiva se comparada às mídias visual e de texto. Uma possível explicação para essa afirmação pode ser a tendência das pessoas focarem mais atenção nas imagens em movimentos que no próprio som, que fica em segundo plano. De acordo com \citeonline{Harb2006} é possível detectar mudanças de cenas em filmes mesmo sem acesso ao conteúdo visual do vídeo, apenas com o som, possibilitando estruturar o vídeo, mesmo que a fala (linguagem) não seja a da mesma pessoa que está escutando.

Exemplos em que somente o fluxo de áudio pode ocasionar mudanças de significado de alto nível podem ocorrer na trilha sonora de um diálogo, que representa a fala de pessoas, seguida por uma mudança de som no plano de fundo ou ainda mudança nos tópicos dos noticiários de televisão ocasionado pela chamada da notícia pela apresentador do telejornal. \citeonline{Jiang2000} relatam que é possível realizar detecção de transição de cenas por intermédio de segmentos elementares da trilha de áudio, os quais são classificados em segmentos de fala (voz de pessoas) e segmentos sem fala (música, som ambiente e silêncio)(Figura \ref{fig:audiodetection}). 

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.50]{./img/audiodetection.png}}
\caption{Visão geral dos métodos de detecção de cena com áudio. Traduzido de \citeonline{Jiang2000}}
\label{fig:audiodetection}
\end{figure}

Pode-se dizer que os trabalhos mais recentes envolvendo detecção de cenas somente com áudio realizam identificação de cenas  quando conseguem classificar o som em eventos coerentes com o conteúdo (gênero) do vídeo avaliado. \citeonline{Lu2006b} adotaram uma abordagem análoga a recuperação de texto por palavras-chave, classificando os elementos de áudio (música, som ambiente e voz) em onze categorias: fala de três pessoas diferentes, músicas, barulho, música com fala, aplauso com fala e aplausos com três músicas diferentes. Essa abordagem investigou segmentos de áudio, de programas de TV, os quais ocasionam transições de cenas. Entretanto, a relação de transição de cenas existentes com a presença de transições que não eram claras ficou na proporção de três para duas, respectivamente, reduzindo a eficácia do método.    

A classificação do áudio em segmentos de vozes e som de fundo é a etapa inicial do método apresentado por \citeonline{Morisawa2005}. Um vetor de características armazena esses segmentos em grupos, transformado-os em índices. As cenas com seus respectivos índices comporta-se como segmento modelo para serem comparadas com amostras de som do vídeo original. A avaliação do resultado foi feita em dois gêneros, entretenimento e telejornais. No entretenimento, a comparação conseguiu identificar segmentos com fala, mas não a fonte da voz corretamente. Em ambos, notou-se que houve sucesso em detectar cenas com música, muito provavelmente devido aos segmentos correspondentes ao som de fundo. Uma vantagem nesse método é a velocidade da recuperação de cenas, menos de 1 segundo por cada sequência comparada.

\citeonline{Harb2006} também fizeram uso da classificação do conteúdo sonoro em seis categorias: diálogo, diálogo calmo, emoção, medo, ação natural e efeitos especiais. Cada unidade sonora (tomada e/ou cenas) é identificada por uma combinação de informações de áudio e adicionada às categorias. Foram avaliados quatro filmes, obtendo uma eficiência de quase 80\% em sua metodologia. Mesmo que os resultados sejam estimados para segmentos que possuam por volta de 60 segundos, segmentos com tamanhos maiores ocasionam poucos erros. Entretanto, em gêneros como filmes, esses segmentos maiores aparecem constantemente.

O aumento na demanda por dados comprimidos foi uma razão para que \citeonline{Yu2009} adotassem o formato MP3 para identificar a transição de cenas, usando para isso uma taixa baixa de ruído SNR\footnote{Signal-to-noise ratio}. Juntamente com a matriz de Transformada Discreta de Cosseno Modificada (do inglês, \textit{Modified Discrete Cosine Transform} - (MDCT)) e um conjunto de técnicas de extração de dados em domínio comprimido de dados, foi implementada uma técnica que detecta segmentos de ruído puro, fala e música, mesmo quando o SNR é tão baixo quanto 0dB (decibéis), resultado comparável aos obtidos em domínios sem compressão.

Por fim, \citeonline{Zhang2010} determinaram o ocorrência de cenas de áudio para transições de programa de TV baseado em algoritmo para detecção de comerciais de TV. Duas técnicas foram aplicadas neste estudo, detecção de silêncio e um algorítmo de espalhamento de áudio. Resultados com precisão acima de 80\% e revocação acima de 95\% foram obtidos, além de proporcionar uma complexidade computacional pequena, demorando apenas 433 segundos para segmentar 9 horas de vídeo.

%\citeonline{Lu2006b} adota uma abordagem análoga a recuperação de texto por palavras-chave. Elementos de áudio são as estruturas básicas dessa técnica  e são caracterizadas por como música, som ambiente e fala. Para fazer a detecção de transição de cenas, uma medida de afinidade semântica é efetuada nos elementos de áudio, a qual consiste em estabelecer dar pesos maiores a esses segmentos por serem temporalmente ligados com outros. Os resultados foram efetuados em um vídeo de uma cerimônia de premiação (entretenimento) e obteve uma classificação de onze elementos de áudio, dentre eles, fala de três pessoas diferentes, músicas, barulho, música com fala, aplauso com fala e aplausos com três músicas diferentes. Esses elementos auxiliaram a detectar as transições de cenas, no entanto a relação de transição de cenas existentes com a presença de transições que não eram claras ficou na proporção de três para duas, respectivamente, reduzindo a eficácia do método. 

%Abordagem que realiza comparação baseado em características sonoras é tratado por \citeonline{Morisawa2005}. Inicialmente o som é classificado em segmentos de vozes e som de fundo. Após, esses segmentos são armazenados em um vetor de características com números específicos de grupos, os quais são transformados em índices. As cenas com seus respectivos índices são comparadas com amostras de som do vídeo original. A avaliação do resultado foi feita em dois gêneros, entretenimento e noticiários. No entretenimento, a comparação conseguiu identificar segmentos com fala, mas não a fonte da voz corretamente. Em ambos, notou-se que houve sucesso em detectar cenas com música, muito provavelmente devido aos segmentos correspondentes ao som de fundo. Uma vantagem nesse método é a velocidade da recuperação de cenas pelo método, menos de 1 segundo por cada sequência comparada.    

%A combinação de informações de áudio foi a metodologia para \citeonline{Harb2006}. Uma estrutura baseada em árvore foi obtida onde o conteúdo sonoro de cada unidade (tomadas e cenas) foi descrito. Foram avaliados quatro filmes, obtendo uma eficiência de quase 80\% em sua metodologia. Para obter esses resultados, foram criadas manualmente seis categorias: diálogo e diálogo calmo, emoção, medo, ação natural e efeitos especiais. Um classificador de áudio foi treinado nessas categorias a fim de verificar o resultado. Mesmo que os resultados sejam estimados para segmentos que possuam por volta de 60 segundos, segmentos com tamanhos maiores ocasionam poucos erros. Entretanto, em gêneros como filmes esses segmentos maiores aparecem constantemente.

\section{Características Multimodais}

\subsection{Características Audiovisuais}
\label{sec:caracaudiovisual}

Como visto no capítulo anterior, a maior parte das pesquisas para segmentação de cenas é relacionada ao uso de características visuais. Entretanto, é possível inferir semântica mais confiável usando outros dados do vídeo, como o áudio, por exemplo \cite{Harb2006}. Além da complexidade do processamento do áudio ser menor, é possível salvar processamento das características visuais usando o áudio para definir algumas respostas definitivas considerando o conteúdo da cena \cite{Wang2000}.

Com o benefício de incluir o som na recuperação de arquivos multimídia, \citeonline{Shao2006} adotaram uma forma de sumarizar vídeos musicais. O método consiste em separar a trilha de música da trilha de vídeo, aplicar técnicas para sumarização na música e detecção de tomadas, por intermédio da análise de conteúdo visual (histograma de cor), alinhando-os posteriormente. A avaliação foi centrada no usuário e obteve resultados comparáveis a sumarização manual. Na pesquisa de \citeonline{Dong2006} fizeram uso das mesmas técnicas no fluxo de áudio, como o \textit{zero-crossing rate} (ZCR), que os autores anteriores, com o objetivo de detectar cenas em documentários por meio de intervalos sonoros. Um desafio nesse trabalho é quando ocorre uma mudança abrupta no áudio, pois o algoritmo pode, erroneamente, detectar a voz do narrador como o som ambiente. O estudo de \citeonline{Danilo2009} faz uso de uma técnica de característica visual (histograma global de cor) e uma de áudio (detecção de silêncio) para segmentar telejornais. Os resultados apresentados compararam o resultado das segmentações realizadas em separado e os resultados com um algoritmo que faz a união das duas técnicas por meio de constantes de tempo (Figura \ref{fig:uniaoaudiovisual}). Embora, a revocação tenha ficado maior, o algoritmo de união conseguiu identificar precisamente mais de 80\% das cenas em todos os telejornais.

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.40]{./img/arquiteturawebmedia.png}}
\caption{Arquitetura da técnica de união das características visuais e de áudio \cite{Danilo2009}}
\label{fig:uniaoaudiovisual}
\end{figure}

Algumas abordagens audiovisuais usam tecnologia de compressão de dados e foram empregadas em vídeos com âmbito médico, esporte e independente de gênero. No primeiro caso, \citeonline{Cao2004} realiza segmentação de cenas em vídeos colonoscópicos, os quais são essenciais para detectar estágios iniciais de câncer no intestino. A avaliação incluiu também o domínio de vídeos sem compressão empregando técnicas distintas. Os resultados foram semelhantes em termos de detecção de cenas, mas o domínio comprimido (MPEG-2) leva um terço do tempo para processar o vídeo. No segundo caso, o algoritmo de inteligência artificial SVM auxilia a detecção de eventos em vídeos (MPEG-2) de jogos de futebol, utilizando como dados relações temporais, movimentos de câmera e descrições de tomadas. Por fim, o último caso, a exemplo do anterior, utiliza não somente vídeo comprimido (MPEG), mas também faz uso do mesmo algoritmo de aprendizado de máquina, o SVM. O emprego desse algoritmo obteve melhores resultados para detectar gêneros de entrevistas e piores para telejornais.     

\subsection{Características Visuais e Textuais}

Alguns trabalhos visam a identificação de cenas explorando somente as características visuais e textuais do fluxo de video. De fato, \citeonline{Misra2010} relatam que os trabalhos melhores avaliados, utilizando a TRECVid como base de dados, fizeram uso de ambas as características, visual e textual. Do mesmo modo, \citeonline{Chua2004} citam que as técnicas de áudio, em comparação com as técnicas de identificação de face e movimento (ambas características visuais), representam os maiores índices de erros para essa mesma base.

Visto que já foram mencionados os conceitos relacionados à extração de características visuais na seção \ref{sec:caracvisual}, faz-se necessário o mesmo para as características textuais. Assim, a Tabela \ref{tab:tabcaractextuais} apresenta os principais meios de se obter informação textuais, bem como as vantagens e desvantagens de cada um.  

\begin{center}	
%\small
\begin{longtable}{|p{100pt}|p{318pt}|}
\caption{Tabela das principais características textuais com suas respectivas vantagens e desvantagens (adaptado de \citeonline{Brezeale2008})}
\label{tab:tabcaractextuais}\\
\hline 
\textbf{Características Textuais} & \textbf{Vantagens / Desvantagens}  \\ 
\hline
\textit{Closed-captions} & Alta eficácia quando não produzido em tempo real, alta dimensionalidade, extração computacionalmente barata \\  
\hline
Reconhecimento de fala (ASR) & Alta taxa de erros \\
\hline
Reconhecimento de caracteres (OCR) & Possibilita a extração de texto em trechos de vídeos que não ocorrem diálogos, computacionalmente caro\\
\hline
\end{longtable}
\end{center}

Juntamente com o uso de características visuais, a maioria dos trabalhos abordam a técnica de reconhecimento de fala (do inglês, \textit{Automatic Speech Recognition}- ASR) \citeonline{Koskela2009}, em grande parte devido ao uso da base TRECVid, pois esta disponibiliza este tipo de metadado, em forma de arquivo de texto associado à cada vídeo. Por conseguinte, os restantes dos trabalhos exploram o reconhecimento de caracteres (do inglês, \textit{Optical Character Recognition}-OCR) \cite{Yu2007} e \textit{closed-captions} \cite{Ogawa2008}.

Após a análise das oficinas dos anos de 2006, 2007 e 2008 do TRECVid, \citeonline{Koskela2009} indicam que o uso de conceitos semânticos associados a informações textuais obtidas por reconhecimento de fala (ASR) fornecem resultados melhores quando comparados com a combinação de recuperação de vídeo baseado em conteúdo e ASR. Um aspecto interessante desse trabalho é o desempenho ruim da recuperação baseada em texto quando analisada sozinha, fato devido ao reconhecimento errôneo de palavras. Outra comparação de abordagens foi realizada por \citeonline{Misra2010}, os quais comparam os resultados de identificação de âncoras utilizando características visuais de cor do MPEG-7 e informações textuais obtidas por \textit{closed-captions}. A integração ocorre quando as transições de ambas as abordagens estão em uma janela de tempo de um segundo de distância entre cada uma, formando apenas uma transição. Essa integração consegue melhores resultados para ambos os conjuntos de telejornais americanos CNN e ABC.

No trabalho de \citeonline{Yu2007} histogramas de cor e textura de Gabor são utilizados para detectar âncoras e compõem o módulo de características visuais, enquanto o módulo textual é formado por ASR e OCR. A informação multimodal é composta pela união de ambos os módulos seguindo uma abordagem de \textit{ranking} com pesos específicos para cada um. Os resultados foram avaliados na conferência TRECVid de 2005 e 2006, obtendo o quarto melhor resultado dentre os trabalhos que fizeram busca manual em 2005, e o sétimo em 2006. \citeonline{Ogawa2008} também faz uso de histogramas de cor para identificar cenas similares em telejornais de países distintos. As similaridades entre as palavras-chaves dos \textit{closed-captions} constituem a informação textual, sendo a integração das abordagens também baseada em uma soma das suas respectivas similaridades. Assim como os trabalhos anteriores, foram comparadas as técnicas aplicadas em separadas e juntas, com melhores resultados para a união de ambas, mas ainda com falsos positivos quando ocorre vinhetas.

\citeonline{Hoi2007} propuseram um arcabouço multimodal baseado em \textit{ranking}. Na parte visual foram utilizadas características de cor (momento de cor), forma (histograma de borda) e textura (transformada wavelet) e na parte textual, um analisador com uma lista de palavras de parada é aplicado no texto fornecido por ASR. Para a construção do ranking multimodal foram combinadas abordagens visuais e textuais juntamente com um método de aprendizado supervisionado (SVM), obtendo melhora de 40\% com uso do \textit{ranking} comparado com somente a técnica textual. Wavelets de textura e momentos de cor também são utilizadas por \citeonline{Xie2007}. Um sistema baseado na frequência de palavras obtidas por ASR é integrado às característica visuais, proporcionando resultados melhores que os propostos para busca de tópicos no TRECVid de 2005 e 2006.
 

\subsection{Características Audiovisuais com Texto}
\label{sec:carcaudiovisualctexto}

Em oposição às técnicas de extração de informação em texto dos trabalhos de características visuais e textuais (ASR), a maioria dos estudos que incluem as três mídias do vídeo utilizam métodos baseado em OCR \cite{Liu2009, Hua2009, Jianping2009}. Assim como os trabalhos que usam mais de uma mídia, as metodologias são similares, sejam nas abordagens visuais com identificação da imagem do âncora com reconhecimento de face \cite{Zhao2006, Jianping2009} e histogramas \cite{Zhao2006, Hua2009}, nas técnicas  de áudio com detecção de silêncio \cite{Zhao2006, Jianping2009, Hua2009} e identificação ou mudança do locutor \cite{Colace2005, Zhao2006}, além de técnicas de integração das mídias com aprendizado de máquina \cite{Colace2005, Jianping2009} ou abordagens com \textit{ranking} \cite{Zhao2006, Wang2008a}. Apesar de apresentar uma metodologia detalhada, o trabalho falha em não apresentar maneiras de validação dos resultados obtidos, atendo-se apenas à apresentação das funcionalidades do arcabouço.

\citeonline{Hua2009} compararam os resultados das técnicas de mídia aplicadas separadas com a técnica multimodal e conseguiu uma melhora de cerca de 11\% na precisão e 5\% na revocação usando a multimodalidade. Os estudos foram baseados em técnicas de OCR para informação textual, comparação de histogramas para visual e detecção de clipes de silêncio com técnicas de extração de energia e \textit{zero crossing rate} (ZCR). Mesmo obtendo resultados satisfatórios, a base de vídeo é restrita a apenas três telejornais de uma mesma emissora, além da fala de entrevistados causarem muitos falsos positivos com o OCR. A técnica de comparação de histogramas de cor para identificação da figura do âncora também fez parte do trabalho de \citeonline{Liu2007}, assim como OCR para texto e detecção de silêncio entre as notícias. 

Fazendo uso de uma base de dados mais extensa, ao contrário da proposta anterior, estudos realizam os testes e validação de suas técnicas em base de vídeos com mais de uma emissora \cite{Zhao2006} e também telejornais de países diferentes \cite{Jianping2009}, gerando técnicas mais abrangentes. \citeonline{Zhao2006} abordaram o uso de características de texturas e cor, dentre elas histograma local de cor, para reconhecimento do âncora e algoritmos para reconhecimento de face como técnicas visuais. Identificar os locutores e procurar momentos de silêncio auxiliaram a técnica multimodal, assim como abordagens para ASR e OCR para informação textual. Duas técnicas de integração de mídias foram elaboradas, uma com pontuação considerando aspectos das características em separado e outra de \textit{ranking} agrupando pesos em uma única lista. A técnica de \textit{ranking} obteve melhores resultados quando analisados em uma base de 60 horas de telejornais das emissoras CNN e ABC, mesmo com o reconhecimento de fala apresentando problemas, não sendo fidedigno à fala do locutor. Com uma base de telejornais de 15 horas do E.U.A e da China, \citeonline{Jianping2009} usaram reconhecimento de face, classificação de áudio com momentos de silêncio, OCR, intensidade de movimento e, por fim, classificação bayesiana para integrar todos os atributos. De modo geral, essa técnica obteve desempenho melhor que as outras duas abordagens comparadas no trabalho, contudo algumas notícias apresentadas sem pausa pelo âncora não foram detectadas e detectadas erroneamente algumas notícias com dois âncoras.

\citeonline{Liu2009} consideraram a legenda das imagens (OCR) a parte principal do sistema multimodal, mesmo considerando que perto das transições tenha momentos de silêncio e/ou mudança de locutor e que a figura da imagem do âncora, identificada por técnicas de reconhecimento de face, apareça na maioria do início das notícias. A técnica multimodal detecta cenas caso duas técnicas indiquem que em um determinado momento ocorre transição, com exceção da técnica de texto, que é capaz de identificar sozinha essa transição. Foram analisados as taxas de erros de segmentação das cenas e a técnica multimodal apresentou o melhor resultado com a menor taxa. Mudança de locutor no áudio é o método também utilizado por \citeonline{Colace2005} como característica de áudio. Histogramas de cor global para detectar mudanças no plano de fundo e ASR para extrair informação textual completam as características que foram utilizadas para obter maior carga semãntica dos vídeos. HMM foi a técnica adotada para integrá-las, formando a técnica multimodal. Uma desvantagem desse estudo ocorre na definição das cenas do tipo notícia, a qual é descrita como sempre tendo a imagem de um âncora no início, a qual é muito restrita, mesmo para a base de oito telejornais italianos analisados.

A análise não somente de telejornais mas de programas de TV em geral foi efetuada por \citeonline{Wang2008a} em cinco noticiários de emissoras diferentes, americanas e chinesas. As técnicas visuais são restritas a histogramas de cor e borda globais e locais classificadas com SVM, silêncio, ZCR, Pitch e outras características fazem parte das características de aúdio e o texto foi obtido por ASR e analisado com LSA (do inglês, \textit{Latent Semantic Analysis}).Na integração um modelo linear com pesos para cada característica foi aplicado. Como esperado, a técnica multimodal teve melhor desempenho em todos os noticiários e técnicas de integração com SVM foram comparadas com a abordagem desenvolvida, obtendo desempenhos muito semelhantes. As características descritas, assim como os resultados descritos, tornam esse trabalho o mais completo até o momento.

Um problema muito comum em todos estes trabalhos que representam o estado da arte de segmentação de cenas em telejornais é a falta de uma definição mais geral para cenas, uma vez que existem três tipos (notícias, vinhetas e comerciais) e várias maneiras diferentes de transição entre elas. Um exemplo é quando um âncora relata a notícia sem aparecer na imagem da TV, apenas narrando os acontecimentos. Desse modo, algumas perguntas ficam em aberto: \textit{No início, quando são apresentadas resumidamente as notícias, elas são consideradas na avaliação dos resultados?}; \textit{As vinhetas fazem parte de alguma transição de notícias?}; \textit{Quando não há imagem do âncora mas uma notícia é apresentada, esta é considerada?}; \textit{As transições entre os blocos de notícias e os comerciais são consideradas?}. Portanto, fica evidente que é necessária uma apresentação conceitual mais abrangente de cenas e suas transições, pois sem isso fica difícil analisar o desempenho das técnicas desenvolvidas pelos autores. Outro ponto não relacionado nos trabalhos multimodais é o uso dos símbolos do \textit{closed-captions} para auxiliar na identificação de transição de notícias, sendo que esse conteúdo indicam as falas dos âncoras e momento exato que isso ocorre. 

Observa-se que nos trabalhos multimodais, \textit{ranking} é abordado com frequência como técnica de integração das mídias, obtendo resultados expressivos quando empregado. Por fim,  mesmo que amplamente utilizadas, \citeonline{Chua2004} citam que o uso de algoritmos de aprendizado de máquina nas técnicas multimodais não descobrem muitas cenas, por conta do não treinamento adequado dos dados. 

%Jianping2009-> Naive

%O uso do texto, juntamente com as mídias de áudio e vídeo, está auxiliando pesquisadores a determinar um nível semântico melhor devido a sua capacidade de obter informação mais precisa contida no tema da cena \cite{Manzato2008}. Como a quantidade de mídias envolvidas no processo de segmentação é maior, métodos de unir tais mídias começam a ficar relevantes. \citeonline{Snoek2005} apresentam duas técnicas que usam aprendizado de máquina supervisionado para unir os dados contidos nas mídias existentes: \textit{Early Fusion} e \textit{Late Fusion}. 

%A primeira integra as características de cada mídia antes dos conceitos da aprendizagem e a segunda reduz os conceitos da aprendizagem das características de cada mídia separadamente, para depois integrá-los em novos conceitos de aprendizagem, ou seja, a abordagem \textit{Late Fusion} trata as características das mídias de maneira separada e possui mais de uma etapa no aprendizado de máquina. Essa última abordagem possui a desvantagem de ser mais complexa e cara computacionalmente dada a quantidade consideráveis de parâmetros. Como algoritmo de aprendizado, \citeonline{Snoek2005} usa a Máquina de Vetor de Suporte (SVM), além de aplicar a abordagem em vídeos do gênero telejornais.

%\citeonline{Wang2008a} foram outros autores que fizeram uso dessa mesma abordagem mas aplicados em gêneros de programas de televisão (entretenimento). A exemplo do trabalho anterior, SVM também foi o algoritmo de inteligência artificial empregado. Dificuldades relacionadas a complexidade da técnica \textit{Late Fusion} também foram mencionadas. Ambos os trabalhos avaliaram as duas técnicas e os melhores resultados foram encontrados na aplicação do \textit{Late Fusion}.

%O uso de SVMs também são relatadas na pesquisa de \citeonline{Pao2008}. Contudo, esse algoritmo faz parte apenas de parte do processamento do áudio na metodologia abordada. Dentre as características relevantes desse estudo está a utilização de palavras, na mídia do texto, para navegar no conteúdo das cenas. Metodologia semelhante também foi descrita por \citeonline{Liu2007}, os quais adotam palavras extraídas do texto e também técnicas de reconhecimento de voz para indexar o conteúdo, possibilitando a recuperação das cenas por intermédio de palavras-chaves. 
%O gênero telejornal foi empregado nos três trabalhos anteriormente citados. 

%\section{Características Visuais com Texto}

\section{Outras Abordagens}
\label{sec:outrasabordagens}

Ao contrário dos métodos convencionais de sistemas baseados em anotações, o padrão MPEG-7 especifica meios de se fornecer informações semânticas descrevendo características audiovisuais do conteúdo multimídia. \citeonline{Lee2003} descrevem uma maneira de gerar índices não apenas com segmentos preliminares do filme mas também acesso não linear por meio de figuras em miniaturas . A Figura \ref{fig:exemplocena} apresenta a estrutura hierárquica utilizando a semântica do MPEG-7. 

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.55]{./img/exemplocena.png}}
\caption{Estrutura hierárquica de representação de cena com MPEG-7 \cite{Lee2003}}
\label{fig:exemplocena}
\end{figure}

%Contudo, não é padronizado um modo de extrair informações de alto nível do conteúdo audiovisual, necessitando de mais esforços no sentido de melhorar o nível semântico obtidos pelas técnicas de extração \cite{vetro2005, bertini2006}. 

O uso de ontologias é outra abordagem recente para representar dados multimídia de uma maneira mais organizada, visando recuperação semântica facilitada. De acordo com a comunidade de Inteligência Artificial, ``ontologia é uma especificação formal de conceitualização'' \cite{Gruber1993}. A conceitualização envolvida no contexto dessa pesquisa refere-se ao domínio de conhecimento associado às características de imagens. Assim, os trabalhos que envolvem extração de informação de alto nível no domínio de imagens em ontologias são separados em dois grupos: os que definem o modelo de dados de acordo com o conteúdo multimídia (características de baixo nível) e os que modelam os dados de acordo com rótulos ou categorias semânticas atribuídas para cada imagem, como por exemplo praia, cidade, natureza, etc.

No primeiro grupo, \citeonline{Liu2007b} relatam que descritores de cor ou textura fornecem modelo de dados que facilitam a recuperação de informação semântica, como por exemplo atribuir os dados: uniforme e região azul como sendo um objeto céu. No segundo, uma ontologia utilizando categorias semânticas pré-definidas (Figura \ref{fig:ontologia}) auxilia o usuário no sentido de permitir que este possa selecionar facilmente palavras-chaves para formular uma busca \cite{Fan2008, Fan2008b}.

Ainda, alguns autores estão fazendo esforços para aproximar o padrão de descrição de informação multimídia, MPEG-7, ficar mais próximo linguagens de ontologias como RDF (do inglês, \textit{Resource Description Framework}) e OWL (do inglês, \textit{Ontology Web Language}) \cite{Hare2006}. 
 
\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.45]{./img/ontologia.png}}
\caption{Visualização da ontologia com categorias pré-definidas \cite{Fan2008}}
\label{fig:ontologia}
\end{figure}

Tecnologias de compressão mais sofisticadas, como o MPEG-4 \cite{MPEG42002}, também possui estudos na área de segmentação semântica. \citeonline{Cavallaro2003} desenvolveram um algoritmo de transcodificação automática de conteúdo de vídeo que suporte múltiplos objetos e suas descrições. A semântica envolvida nesse estudo está relacionada a detecção de movimentação, especificamente a separação de objetos em movimento do plano de fundo, e aos descritores extraídos dos objetos de vídeo.
 
Outra abordagem para a recuperação de cenas considera a interação com o usuário como o caso da Resposta por Relevância (do inglês, \textit{Relevance Feedback}). Essa extração acontece por intermédio de algoritmos que tentam processar as intenções do usuário em tempo real. A medida que o usuário escolhe imagens de acordo com uma determinada busca, algoritmos de aprendizado de máquina captam essa escolha e tentam aprender com a resposta do usuário. Realocação dinâmica de pesos nas características de baixo nível pode ser efetuada quando o usuário realiza a interação \cite{Liu2007b, Deb2004}.

A extração de texto de vídeos é uma metodologia que pode ajudar na classificação de vídeos. \cite{Manzato2008} realizam a comparação de técnicas como  algoritmos genéticos e índice semântico de latência (do inglês, \textit{Latent Semantic Indexing}-(LSI)) para determinar qual fornece o melhor resultado na classificação de vídeos de noticiários que possuam texto no formato de \textit{closed-captions}. Apesar de LSI ser amplamente aplicada em recuperação de informação, seus resultados foram piores que os obtidos com algorítimos genéticos. Dentre as razões está o suporte a polissemia\footnote{Polissemia são palavras que possuem mais de um significado.}, que origina falsos positivos na classificação e o pequeno volume de texto empregado na amostra da metodologia. \textit{Closed-captions} continuou a ser utilizado por \citeonline{Manzato2010} para identificar cenas em telejornais.  Nesse trabalho os autores desenvolveram uma técnica que considera o usuário como produtor e fornecedor de conteúdo. Por meio de um mecanismo de busca, um arcabouço considera a combinação de diferentes critérios de pesquisa, como: características visuais (histograma local de cor) baseada em amostras de imagens (quadros-chave), texto obtido por intermédio de \textit{closed caption} e reconhecimento de faces. Um algoritmo que faz a união desses critérios foi proposto, obtendo melhores resultados do que o uso das técnicas em separado, melhorando a experiência final do usuário com esse tipo de conteúdo.

Ferramentas que fazem uso de algoritmos de aprendizado máquina em ambas as categorias, supervisionado e não supervisionado, também conseguem obter um nível semântico mais avançado \cite{Liu2007}. Na categoria supervisionado, SVM, classificador Bayesiano \cite{jin2004} redes neurais \cite{town2001} e árvores de decisão \cite{sethi2001} são utilizados para prever categoria semântica a partir de um conjunto de entrada. Erros de classificação durante a fase de treinamento e o fato de serem computacionalmente caros são as suas principais restrições. Contudo, os algoritmos não supervisionados, como \textit{k-means} \cite{bilenko2004} e Corte Normalizado (do inglês, \textit{Normalized Cut}- NCut) \cite{ng2002}, fornecem, de modo geral, melhores resultados que os supervisionados, pois tendem a agrupar funcionalidades por semelhança, diminuindo as diferenças entre os dados de um mesmo grupo. Bons resultados em recuperação de imagens baseada em conteúdo são obtidos usando a teoria de Bayes \cite{vasconcelos2004} para classificação por probabilidade.  
%Bulcão et al, destaca que "Quanto mais rica a semântica da linguagem de ontologia, mais ineficiente é a sua capacidade de inferência" devido ao fato que as construtores definidas linguagens como esquemas rdf são muito simples para representar cenários mais complexos.  
%%um falando de relevance feedback(An overview of content-based image retrieval Deb2004 techniques e Liu et al- manzato

\section{Considerações Finais}

Como apresentado neste capítulo, as pesquisas nos últimos anos estão adotando diferentes abordagens em busca de um resultado mais eficiente na área de segmentação de cenas. O processamento de características específicas do vídeo, como as visuais, sonoras e textuais ou combinação delas, como pode ser observado também no apêndice deste trabalho, é uma tendência que visa conseguir melhores resultados.

Outro ponto importante nos trabalhos é a especificação de um determinado gênero do vídeo para aplicar as suas respectivas metodologias, tornando mais fácil a extração das cenas. Em alguns gêneros, como os telejornais, as pesquisas avançam consideravelmente em direção à multimodalidade das técnicas, entretanto, apresentam problemas em utilizar uma definição mais geral para os segmentos analisados (cenas). A abordagem de identificação do âncora é o principal indício do início de uma cena, mas isso não é regra, visto que dois âncoras ou mesmo uma imagem sem a figura de quaisquer âncora(s) pode indicar o início de uma cena. Logo, histogramas de cor são usados para identificar a imagem de um âncora com determinado plano de fundo, seja ele estático (com uso de histogramas globais) ou dinâmico (com uso de histogramas locais), mas falha em detectar situações em que ocorrem mais de um âncora na mesma imagem. Para contornar este problema, reconhecimento de faces é uma abordagem que consegue bons resultados, no entanto, não resolve a questão de uma cena iniciar sem a figura de âncora algum, no caso em que somente a fala do âncora indica a transição de cena. Uma alternativa a essa situação é recorrer às características de áudio e texto. Portanto, faz-se necessário desenvolver um conjunto de técnicas multimodais que detectem todas as possíveis situações de transições de cenas.

Com os trabalhos apresentados neste capítulo, observa-se que as ferramentas que, de fato realizem recuperação confiável de conteúdo multimídia para usuários finais ainda é uma necessidade a ser atendida, tanto pela área comercial quanto pela acadêmica. Contudo, as pesquisas avançam em direção ao estreitamento da lacuna semântica ocasionado pelos trabalhos que realizam a recuperação de informação em vídeos digitais. 