%\thispagestyle{fancy}
\chapter{Conceitos, Definições e Metodologias}
\label{chap:conceitos_e_definicoes}

\section{Considerações Iniciais}
\label{sec:consideracoes_iniciais1}
%o q é o vídeo e seus formatos
O vídeo, formado por sinais analógicos ou digitais, tem como funções a captura, armazenamento, transmissão ou apresentação de imagens em movimento. Seu uso principal, a partir de meados do século XX, foi concebido pelo principal meio de comunicação ainda hoje, a televisão. O princípio de funcionamento das primeiras versões desse aparelho era baseado em transmissões analógicas, as quais utilizavam ondas eletromagnéticas contínuas. Todavia, com a evolução tecnológica, os vídeos passaram a ser disponibilizados em outro tipo de formato, o formato digital. 

%o q é video digital e quais aparelhos o utiliza
O vídeo digital é formado por um sinal com valores discretos (descontínuos) no tempo e em amplitude, definido para determinados instantes de tempo e assumindo um conjunto de valores finito. Assim, as funções definidas anteriormente para o vídeo são mais eficientes e eficazes quando utilizado esse tipo de formato. A sua maior aplicabilidade encontra-se em equipamentos computacionais e com tendência de substituição dos televisores analógicos por modelos digitais, ocasionando o aumento da qualidade visual e possibilidades de interação com o conteúdo assistido (TV Interativa). 

%a necessidade do video digital e aplicabilidades
A popularidade do uso de vídeos digitais são consequências de fatores que estão ocorrendo concomitantemente: avanços na tecnologia de compressão, maior acesso às câmeras digitais, dispositivos e sistemas com alta capacidade de armazenamento, aumento do uso da Internet e redes banda larga~\cite{Hanjalic2004}. Esses fatores ocasionam maior demanda por aplicações que fazem uso de vídeo como um importante mecanismo de transmissão de informações audiovisuais. Exemplos dessas aplicações podem ser encontradas, inclusive, em áreas sociais como saúde, educação e segurança, respectivamente com aplicabilidades específicas na telemedicina, educação à distância por meio do aprendizado eletrônico, em sistemas de monitoramento e vigilância, entre outras.

Além de aplicações em áreas sociais, outros cenários são beneficiados em sua utilização. Áreas como publicidade e propaganda e \textit{marketing} fazem uso cada vez maior desse conteúdo para repassar ao cliente a necessidade da obtenção de um determinado produto. Na Internet, sítios como o Youtube \footnote{http://www.youtube.com} armazenam uma vasta quantidade de vídeos caseiros, ganhando milhões de usuários ao redor do mundo. Entretanto, outras áreas sofrem problemas com o aumento dessa popularidade, como ocorre com a indústria cinematográfica, a qual está sofrendo grandes perdas com a difusão sem autorização desse conteúdo, principalmente quando é feito o comércio ilegal de produtos com direitos autorais, ocasionando o problema da pirataria de vídeos.

%utilização de video em massa e desafio de manipulação do vídeo
A grande diversidade de aplicações denotam a importância desse conteúdo multimídia como um poderoso meio de comunicação. A quantidade de vídeos que são produzidos, assistidos, editados, armazenados, transmitidos e trocados entre usuários ocorre devido à possibilidade de realizar o processamento de vídeos de maneira automática. Entretanto, se o objetivo do usuário é, por exemplo, localizar um determinado segmento de vídeo de seu interesse em uma coleção de arquivos desse tipo, a única maneira é assistir a cada segmento desde o começo utilizando operações de avanço rápido (\textit{fast-forward}) e retrocesso rápido (\textit{fast-backward}) até que ele encontre o segmento desejado~\cite{Zhu2008a}. Por meio desse exemplo fica evidente que a procura linear tem baixa eficiência e consome muito tempo, tornando o processo de busca inadequado, requisitando mecanismos de recuperação de informação mais rápidos e melhores.  

%áreas e seus propósitos
Portanto, a extração dos dados do vídeo com o objetivo de obter informações sobre seu conteúdo é um problema de pesquisa na literatura, tornando um desafio nas áreas que realizam análises em vídeo baseados em conteúdo. Recuperação de Vídeo Baseado em Conteúdo (do inglês, \textit{Content-Based Video Retrieval} - CBVR) e Análise de Conteúdo de Vídeo (do inglês, \textit{Video Content Analysis}) são áreas que tentam contornar e/ou diminuir este problema. A Figura \ref{fig:algoritmos} ilustra como as áreas citadas abordam a recuperação de informação em vídeo. Na etapa inicial, são desenvolvidas técnicas ou algoritmos que fazem o processo de extração de informação do material. Após, estes são aplicados no vídeo com o intuito de detectar trechos que contenham pessoas, objetos ou eventos para que possam ser identificados e geralmente representados como imagens no dispositivo computacional. Por fim, ao escolher e selecionar uma imagem, o usuário visualiza o segmento do vídeo associado ao trecho identificado, extraído do vídeo original.     

\begin{figure}[h!]
\centering  % figura centralizada
\fbox{\includegraphics [scale=0.65]{./img/FIGURA4.png}}
\caption{Algoritmos aplicados nos vídeos digitais que são desenvolvidos para facilitar a recuperação de seus conteúdos. Adaptado de~\citeonline{Hanjalic2004}}
\label{fig:algoritmos}
\end{figure}


\section{Estrutura do vídeo digital}
\label{sec:estrutura_e_analise_do_video}

O processo de extração de informação nos vídeos digitais tem como foco auxiliar o usuário no acesso a seu conteúdo. Contudo, atualmente, o modo tradicional de acesso ocorre de maneira linear, sendo necessário que o usuário procure o segmento desejado desde o começo. Para que o acesso seja efetuado de modo não linear é necessário entender como é constituído este tipo de componente.

Também chamada de representação hierárquica~\cite{Li2001,Rui1998}, a estrutura do fluxo do vídeo digital é constituída de níveis ou camadas, as quais são formadas por intermédio da análise de seu conteúdo (Figura \ref{fig:estrutura_video2}). Os algoritmos de extração de dados atuam em uma ou mais dessas camadas fornecendo, algumas vezes, informações para outros algoritmos desenvolvidos nas camadas superiores. Particularmente, os algoritmos da área de Análise de Vídeo Baseado em Conteúdo estruturam o conteúdo do vídeo seguindo essa abordagem~\cite{Ngo2001}. 

\begin{figure}[htb]
\centering  
\fbox{\includegraphics{./img/estrutura_video2.png}}
\caption{Estrutura do fluxo de vídeo digital}
\label{fig:estrutura_video2}
\end{figure}

%apresentar as camadas da figura
Sendo o vídeo uma sequência de imagens estáticas, essas imagens estão presentes na estrutura e são chamadas de quadros. As tomadas são os seguimentos da camada acima, constituída por sequências de imagens (quadros) geradas por uma câmera do momento em que é iniciada a gravação até o momento do término da mesma \cite{Hampapur1994}. As cenas são definidas como um grupo de tomadas com conteúdo correlacionado \cite{Zhao2001}, também chamadas de unidades semânticas. A última camada é o próprio vídeo, ou vídeo em sua forma ``crua'' (do inglês, \textit{raw video}). Basicamente, a diferença entre as camadas de tomadas e cenas está na natureza da análise, pois quanto mais baixo no nível da estrutura, maior a eficácia das técnicas e menor a complexidade computacional. Entretanto, quanto mais alto no nível, maior a dependência do gênero do vídeo (e.g. telejornal, evento esportivo, filmes de ação, etc)~\cite{Zhang2006}.  

%apresentar diferentes tipos de representação do video 
Embora a representação da estrutura de vídeo (Figura \ref{fig:estrutura_video2}) seja considerada um consenso na comunidade acadêmica~\cite{Sural2005,Oh2005,Zhao2001}, alguns autores utilizam outras representações (Figura \ref{fig:representacaoestrutura}). Mesmo não sendo iguais, há muita semelhança entre todas as apresentadas, havendo mudanças somente no acréscimo de uma camada na estrutura, seja entre as camadas de tomadas e cenas ou entre as camadas de cenas e o vídeo completo. No primeiro caso, é apresentada uma estrutura com uma camada Grupo que representa uma etapa responsável pelo agrupamento de segmentos de tomadas~\cite{Rui1998}(Figura \ref{fig:representacaoestrutura1}). No segundo caso, é formada uma camada Programa para representar possíveis episódios de uma série de TV (camada Vídeo)~\cite{Al-Hames2006} (Figura \ref{fig:representacaoestrutura2}). Em ambos fica evidente que o tipo de estrutura é elaborada de acordo com a metodologia sugerida, dependendo do nível de granulação de informação que o autor pretende trabalhar.

\begin{figure*}[!htb]
%talvez tenha q tirar o fbox
\fbox{
\centerline{
\subfigure[\cite{Rui1998}]{\includegraphics[width=7.5cm]{./img/estrutura_video_2.png}
\label{fig:representacaoestrutura1}}
\hfil
\subfigure[\cite{Al-Hames2006}]{\includegraphics[width=7.5cm]{./img/estrutura_video_4.png}
\label{fig:representacaoestrutura2}}
}}
\caption{Outras representações para estrutura de vídeo digital}
\label{fig:representacaoestrutura}
\end{figure*}

Apesar do processo de análise de vídeo ser realizado de modo qualitativo, buscando resultados eficazes, \citeonline{Al-Hames2006} faz uma análise quantitativa da estrutura, proporcionando uma idéia da quantidade de cada estrutura e da complexidade de trabalhar com vídeos digitais. As estimativas apresentadas nessa análise compreendem uma aproximação de vinte e cinco quadros por segundo, muitas centenas de tomadas por hora e cerca de cem cenas por hora.   

\section{Análise do Vídeo Digital}   
%falar dos grupos da analise de conteudo de vídeo (3 grupos livro)
A identificação de tais estruturas é uma etapa essencial na criação de mecanismos que viabilizam o acesso ao teor do material disponível no vídeo, porém constitui apenas uma etapa no gerenciamento desse conteúdo multimídia. A área de Análise de Vídeo Digital Baseado em Conteúdo é composta por três grupos distintos, cada qual contendo algoritmos que realizam análise no conteúdo de vídeo \cite{Hanjalic2004}:

\begin{itemize}
\item Análise da estrutura do vídeo: relacionada à segmentação de vídeo em estruturas temporais de baixo nível (tomadas) ou alto nível (cenas).
\item Indexação de conteúdo de vídeo: designa automaticamente pedaços dos dados do vídeo para categorias pré-especificadas no formato de rótulos (\textit{e.g.} alegria, futebol no estádio, criança chorando, etc). A ligação para essas categorias ocorre por meio de elementos denominados índices, possibilitando a recuperação posterior de cada segmento por meio desses elementos.
\item Representação e abstração do conteúdo de vídeo: constrói resumos compactos mas compreensíveis dos segmentos de vídeo. O objetivo dessa etapa é comunicar de maneira eficiente e eficaz o conteúdo do vídeo para o usuário.
\end{itemize}

De modo resumido, a análise da estrutura extrai do vídeo estruturas temporais menores (tomadas ou cenas) \cite{Dimitrova2002}. A indexação do conteúdo de vídeo designa esses segmentos para um grupo de categorias, formando índices que relacionam os segmentos. Por fim, na representação e abstração de conteúdo, os índices são disponibilizados e apresentados aos usuários de maneira que estes possam navegar no conteúdo do vídeo. Disponibilizar esse tipo de conteúdo multimídia visando modos de busca e interação com o usuário também é uma maneira de realizar adaptação e personalização de conteúdo \cite{LUM2002,barrios2005}.

O método de segmentar um vídeo constitui da extração de suas partes relevantes. A segmentação pode ser classificada como espacial ou temporal \cite{Magalhaes2004}. A segmentação espacial foca as suas principais técnicas em dividir o vídeo considernando determinadas características espaciais (objetos), detecção de faces e reconhecimento de objetos que não estejam no plano de fundo. Na segmentação temporal são classificados segmentos com menor duração de tempo e com características semelhantes, eventos como o gol em um vídeo de futebol ou explosões num filme de ação são exemplos dessa segmentação. O foco deste trabalho está em recuperar informações baseadas em eventos, visto que o usuário assiste e recorda de vídeos em termos de eventos, episódios ou histórias \cite{Wang2003}.

 %diferenciar os tipos de segmentações (sintatica e semantica) 
\citeonline{Wang2003} descrevem a segmentação temporal do vídeo como sendo de dois tipos: a sintática e a semântica. A segmentação sintática ocorre quando a técnica ou algoritmo é empregado para identificar tomadas, visto que sua análise pode ser efetuada extraindo dados dos quadros que a compõem. Na segmentação semântica é proposta a identificação de cenas, as quais requerem um melhor entendimento dos tópicos presentes num determinado conjunto de tomadas. 
%dizer abordagens adotodas dependendo do tipo do algoritmo (automatica, semi automatica, ....)
A elaboração das metodologias nos algoritmos ou técnicas usados para realizar a etapa de análise de estrutura do vídeo possui algumas variações. A seguir, são descritas as abordagens consideradas nesse processo \cite{Hanjalic2004,Ngo2001}:
\begin{itemize}
\item Domínio com compressão X domínio sem compressão: o processamento de vídeo digital demanda muito tempo computacional e uma grande quantidade de memória. Para que ambos, tempo e espaço, sejam reduzidos, abordagens que manipulam vídeos diretamente em formato comprimido tem se tornado uma prática constante.
\item Técnica automática X técnica semi-automática: para alcançar o melhor nível de interação com o usuário, a aplicação deve requisitar somente o nível de interação necessário. Enquanto sistemas de vigilância devem funcionar de modo automático, detectando movimentos suspeitos e avisando ao usuário, outros sistemas fornecem liberdade ao usuário para determinar, por exemplo, o tamanho dos índices de um certo filme ou os melhores lances de um esporte.   
\item Uso de várias mídias: além da parte visual, o vídeo pode ser acompanhado de outras mídias como áudio e texto. O fluxo de áudio pode consistir de música, representar vozes (fala), som ambiente ou ainda uma mistura dos três. Os textos geralmente representam a tradução de uma língua estrangeira, disponibilizados em formatos de legendas, ou descrevendo qualquer som presente no vídeo (palmas, passos, risos, músicas, fala, etc), por meio do \textit{closed caption}. Caso o conteúdo do vídeo seja composto por mais de um tipo de mídia, o ideal é que as informações de cada mídia sejam agrupadas de maneira que proporcione maior significado ao conteúdo, ou seja, maior semântica ao vídeo.    
\end{itemize}

Outra abordagem discutida é em relação ao momento em que as técnicas são empregadas, pois a transmissão do vídeo pode ser efetuada em tempo real~\cite{Correia2004}. Portanto, uma nova divisão das abordagens faz-se necessária: as que realizam processamento em tempo real ou as que realizam em vídeos já armazenados, também conhecida como \textit{off-line}.

Nas sub-seções a seguir são detalhadas as estruturas temporais que compõem o fluxo de vídeo digital.

\subsection{Detecção de Tomadas}

O desenvolvimento de algoritmos nessa área tem a maior e mais rica história na área de análise de conteúdo de vídeo. Maior porque é a área que iniciou, de fato, as tentativas de detecção automática de cortes em vídeos, e mais rica porque contem a maioria dos trabalhos publicados na área desde então~\cite{Hanjalic2004}. Os trabalhos que abordam a detecção de tomadas ou detecção de transição de tomadas fornecem a base para quase todas as abordagens de análise de conteúdo de vídeo de alto nível (cenas), além de ser também um pré-requisito para o desenvolvimento da estrutura do conteúdo do vídeo. As definições sobre essa estrutura variam, \citeonline{Koprinska2001} definem a tomada como uma sequência linear de quadros retirados de uma única câmera, enquanto \citeonline{Dimitrova2002} identifica o limiar da tomada como pontos de edição ou pontos em que ocorrem ligamento/desligamento da câmera. Por meio dessas definições nota-se que tomadas são segmentos compostos por quadros sendo dependente das ações de câmeras.

Entre duas tomadas consecutivas ocorre uma transição, a qual é separada em dois grupos: abrupta ou gradual. Também chamada de corte, a transição abrupta é mais fácil de ser detectada, pois consiste de uma mudança instantânea entre uma tomada e outra, ocorrendo como um corte entre dois quadros consecutivos (quadros 2 e 3) (Figura \ref{fig:corte})~\cite{Koprinska2001}.

\begin{figure}[h!]
\centering
\fbox{\includegraphics{./img/corte_tomada.png}}
\caption{Transição abrupta de tomada}
\label{fig:corte}
\end{figure}

A transição gradual de tomadas é mais difícil de ser realizada e pode ser dividida em duas classes: aquelas que ocorrem simultaneamente, mas que afetam gradualmente todo o pixel da imagem e àquelas que afetam abruptamente todo um conjunto de pixels, com este conjunto mudando em cada quadro \cite{Joyce2006}. Transições como \textit{fade in/out} e dissolução fazem parte do primeiro grupo e \textit{wipes} constituem o segundo, todas essas descritas e ilustradas a seguir:

\begin{itemize}
\item Dissolução: quando uma imagem sobrepõe outra de modo gradativo, isto é, estendendo em vários quadros (Figura~\ref{fig:diss}).

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.80]{./img/diss.png}}
\caption{Dissolução \cite{Porter2003}}
\label{fig:diss}
\end{figure}


\item \textit{Fade in} e \textit{Fade out}: respectivamente, quando uma imagem escura clareia gradativamente ou o oposto, imagem clara escurece gradativamente  (Figura \ref{fig:fades}). Esse pode ser considerado um caso especial de dissolução, uma vez que ocorre gradativa sobreposição de quadros claros à escuros ou o oposto \cite{Ngo2001}. 

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.70]{./img/fades.png}}
\caption{Transição \textit{fade out} seguida por \textit{fade in} \cite{Koprinska2001}}
\label{fig:fades}
\end{figure}

\item \textit{Wipes}: quando uma imagem é  ``empurrada'', ``dobrada'' de alguma modo ou direção, até desaparecer, dando lugar a uma outra imagem. A Figura \ref{fig:wipes} representa quatro diferentes tipos de \textit{wipes}.

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.90]{./img/wipes.png}}
\caption{Diferentes tipos de \textit{wipes} \cite{Joyce2006}}
\label{fig:wipes}
\end{figure}

\end{itemize}

Devido a maior parte do processamento computacional ser dedicada a esses algoritmos de detecção de transição de tomadas, o seu nível de complexidade deve ser baixo. Entretanto, minimizando o nível de complexidade acarreta numa menor taxa de detecção de erros. Um exemplo é o problema da transição gradual de tomadas as quais os efeitos editáveis estão sobrepostas em movimentos de objetos e câmera. Para eliminar a influência da movimentação no comportamento do sinal entre a transição, estimativas e compensação de movimentação podem ser aplicados. Contudo, isso é computacionalmente caro, justificável apenas em casos onde a informação de movimento está realmente disponível, como em vídeos comprimidos (e.g. MPEG), tornando o desempenho do detector dependente das características particulares de codificação~\cite{Hanjalic2004}. 

Quando um vídeo é segmentando em tomadas, dois problemas devem ser considerados. O primeiro é a capacidade de distinguir entre uma transição de tomada e uma mudança ocorrida dentro de uma tomada. A maioria das mudanças normais são de movimentos de objetos ou movimento de câmera. Durante esses movimentos, o conteúdo das imagens podem alterar drasticamente, como por exemplo, a movimentação de objetos grandes ou a rápida movimentação da câmera torna difícil a identificação de transição de tomadas. O segundo problema é a capacidade de distinguir entre transições graduais e quadros sem transição. Quando transições graduais estão envolvidas, duas tomadas estão mescladas no processo de edição: a evolução de uma tomada à outra ocorre ao longo de vários quadros, sendo cada um diferente do outro apenas por pequenos detalhes. Usando o método de detecção normal de corte (abrupto), esse efeito especial pode não ser detectado como uma mudança de tomada. Portanto, é necessário o uso de algoritmos dedicados para transição gradual de tomadas.

\subsection{Detecção de Quadros-Chave}

Um elemento importante na extração de informação utilizando características visuais é o quadro-chave (do inglês, \textit{key-frame}). Segundo \citeonline{Yinzi2010}, a extração de quadros-chave pode ser dividida em três classes distintas: baseada em amostragem, baseada em segmentos e baseada em tomadas. A abordagem baseada em amostragem é a mais simples e seleciona os quadros-chave capturando quaisquer quadros por meio de um intervalo fixo de tempo. A baseada em segmentos agrupa os quadros ou tomadas que possuam similaridades, de cor, textura e/ou movimento, em um conjunto de segmentos  com um algoritmo de agrupamento, extraindo quadros-chave de cada segmento. A complexidade do algoritmo e a dificuldade de determinar o número de segmentos são suas desvantagens. Por fim, a abordagem baseada em tomada é a mais comum, a qual realiza a segmentação temporal em tomadas e seleciona quadro(s)-chave para cada tomada aplicando técnicas que envolvem a seleção do primeiro quadro da tomada, média de \textit{pixels}, média de histograma de cor ou considera o conteúdo. Tanto a abordagem de extração por amostragem quanto por tomada (no caso de extrair mais de um quadro-chave por tomada) podem ocasionar um volume muito grande de quadros-chave proporcionando redundância de informação e diminuindo a eficácia das técnicas do próximo nível da estrutura do vídeo, ou seja, técnicas de segmentação de cenas.  A vantagem da segmentação baseada em tomada, usando um quadro-chave por tomada é diminuir a redundância e ser mais adequada a tomadas com poucas mudanças ou movimentos de câmera, como acontece no telejornal \cite{Zhang2002}.

\subsection{Detecção de Cenas e a Lacuna Semântica}

%definição de cena aliada a expressão "semântica"
Enquanto a detecção de tomadas é o primeiro passo para a realização da análise do vídeo, a detecção de cenas é o primeiro passo em direção a compreensão semântica do vídeo digital~\cite{Chen2008a}. Seguindo o fluxo contrário dessa definição, nota-se que à compreensão semântica depende de estruturas denominadas cenas. Segundo \citeonline{Aner-Wolf2004}, cena é uma coleção de tomadas consecutivas que estão relacionadas umas com as outras por meio de conteúdo semântico.  A expressão ``semântica'' também está presente na definição de \citeonline{Zhai2006}, afirmando que uma cena é um grupo de tomadas relacionadas semanticamente e coerente de acordo com um tema ou assunto. Com base nessas definições é possível identificar algumas características desse segmento: \textit{i)} são compostos por um grupo de tomadas; \textit{ii)} essas tomadas devem conter um tema ou assunto semelhante entre si; \textit{iii)} informação semântica deve estar presente. 

%definir pq o nome segmentação semântica de vídeo
De acordo com o dicionário Houaiss~\cite{Houaiss2001} a palavra semântica é apresentada como o estudo do significado das palavras, contudo, a unidade relevante na área de segmentação de vídeo não são palavras, mas sim segmentos de vídeo. Assim, a semântica relacionada ao vídeo denota-se ao seu próprio significado ou de um seguimento associado ao mesmo. Portanto, a segmentação semântica de vídeo, ou extração de cenas, está relacionada com a extração de unidades que tenham significado similares (semântica), de acordo com um determinado tema ou assunto e decorrente de um agrupamento de tomadas \cite{Sural2005}.

%dizer o q é informação semantica e relacionar com lacuna semantica
Contudo, determinar o significado de uma cena não é uma tarefa simples. A distância entre a informação que pode ser extraída do conteúdo visual e a interpretação ou significado desses dados por um usuário em determinada situação é visto como uma questão em aberto, também conhecida como lacuna semântica \cite{Smeulders2000}. As informações extraídas do vídeo, geralmente de estruturas como quadros e tomadas, são chamadas de características de baixo-nível, e são representadas por dados como cor, forma, textura, etc., possibilitando o uso de diversas técnicas de extração (Tabela \ref{tab:tabcaracbaixonivel}). %Enquanto que as informações compreendidas pelo usuário são ditas como de alto-nível, compreendendo semântica.      

\begin{center}	
\small
\begin{longtable}{|p{80pt}|p{338pt}|}
\caption{Tabela de algumas características de baixo-nível com suas respectivas técnicas \cite{Hanjalic2004}}
\label{tab:tabcaracbaixonivel}\\
\hline 
\textbf{Características} & \textbf{Técnicas}  \\ 
\hline
cor & distribuição de cor, momentos de cor\\  
\hline
textura & energia de textura, contraste, repetividade, complexidade, modelos estocásticos, modelo auto-regressivo, auto-correlação\\
\hline
forma & estatísticas de borda, parâmetros de curvatura\\
\hline
áudio & \textit{pitch}, espectro de frequência, características de sinais temporais, fonemas, \textit{zero-crossing rate}\\
\hline
movimentação & direção e intensidade do movimento, coerência de campo de movimentação\\
\hline
relacional & relações direcionais e topológicas entre linhas, regiões ou objetos \\
\hline
\end{longtable}
\end{center}

A interpretação que o usuário fornece de determinado segmento do vídeo são as informações de alto nível, as quais são encontradas entre as transições de seguimentos semânticos~\cite{Hanjalic2004}. Tais informações representam as cenas, ou eventos, e podem ser encontradas nos vídeos dos mais variados gêneros: um evento em vídeo de esporte (como um gol no futebol e uma cesta no basquete), determinada notícia em um telejornal (como notícia de política, economia, clima, etc.), cenas em filmes de ação (explosões e corridas de carro).    

Desse modo, o espaço entre as características de baixo nível e as de alto nível representa a lacuna semântica (ilustrada na Figura \ref{fig:lacunasemantica}). Essa lacuna é a responsável por se considerar a detecção de tomadas como sintática e o detecção de cenas como semântica. Enquanto que para detectar tomadas, as características de baixo nível são suficientes, na detecção de cenas é necessário obter as características de alto nível \cite{Wang2003}.

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.70]{./img/lacunasemantica.png}}
\caption{Representação da lacuna semântica. Adaptado de~\cite{Hanjalic2004}}
\label{fig:lacunasemantica}
\end{figure}

A Figura \ref{fig:piramide} apresenta uma relação dos segmentos, representados por tomadas e cenas, e suas respectivas características associadas, baixo e alto nível, respectivamente.   

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.50]{./img/piramide.png}}
\caption{Pirâmide da estrutura do conteúdo do vídeo. Traduzido de~\cite{Hanjalic2004}}
\label{fig:piramide}
\end{figure}

As aplicações relacionadas a segmentação/identificação de cenas ocorrem em vários domínios, fornecendo diversos benefícios: em filmes menores a segmentação de cenas provê capítulos que correspondem a diferentes subtemas do filme; em vídeos de televisão, a segmentação pode ser usada para separar os comerciais dos programas comuns. Nos telejornais, a segmentação pode ser utilizada para identificar diferentes histórias jornalísticas (tal como clima, economia, política, esportes, etc). Em vídeos caseiros, pode ajudar os usuários a organizar logicamente os vídeos relacionados a eventos distintos (aniversários, formatura, casamento, férias, etc.) \cite{Zhai2006}.

Ao passo que as cenas possuem uma semântica associada ao seu conteúdo e esse conteúdo varia de acordo com os inúmeros domínios, os quais alguns foram relacionados anteriormente, \citeonline{Snoek2005a} propôs um modelo de granularidade chamado de indexação semântica hierárquica. Tal modelo separa os temas/domínios de vídeos já estudados na literatura acadêmica em 5 níveis, descritos a seguir:

\begin{enumerate}
\item \textbf{Propósito}: conjunto de vídeos que compartilham idéias similares;
\item \textbf{Gênero}: conjunto de vídeos que compartilham estilos similares;
\item \textbf{Sub-gênero}: um subconjunto de vídeos que possuem similaridades no conteúdo;
\item \textbf{Unidades Lógicas}: partes contínuas de um conteúdo de vídeo;
\item \textbf{Eventos nomeados}: pequenos segmentos que possuem um significado que não se altera durante o tempo;
\end{enumerate}

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.60]{./img/categoriavideos.png}}
\caption{Modelo de indexação semântica hierárquica de vídeo proposto por ~\citeonline{Snoek2005a}}
\label{fig:indexacao_semantica}
\end{figure}

A Figura \ref{fig:indexacao_semantica} apresenta os temas/domínios mais comuns no contexto acadêmico, assim como a disposição dos mesmos no modelo de indexação semântica hierárquica. No primeiro nível, o propósito do vídeo é composto por três seguimentos: entretenimento, informação e comunicação. Exemplos de gêneros (segundo nível) varia de filmes, telejornais à comerciais. O terceiro nível são compostos por diferentes sub-gêneros como filme de terror ou uma partida de hóquei no gelo. Exemplos de unidades lógicas, no quarto nível, podem ser diálogos em um filme de drama, o primeiro quarto em um jogo de basquete ou notícia de clima em um telejornal e, por último, no nível mais baixo, são exemlos de eventos nomeados variam de explosões em filmes de ação, gols em uma partida de futebol, a cotações de ações em notícias de economia de um telejornal.

\subsection{Cenas em Telejornais}

Como já mencionado, definir unidades correlacionadas semanticamente (cenas) não é uma tarefa trivial, pois existe o problema da lacuna semântica. Quando o gênero do vídeo analisado é o telejornal torna-se mais complicado porque este possui a peculiaridade de abordar assuntos bem distintos em seu conteúdo. Todavia, mesmo sendo um tema de pesquisa em aberto ainda hoje, trabalhos mais antigos já exploravam a importância de identificar esses segmentos. \citeonline{Altheide1985} utilizou o termo ``unidades de informação'' para representar cenas, enquanto \citeonline{Graber1990} utilizou o termo ``cenas visuais'' e, posteriormente, ``unidades físicas'' foi a denominação adotada por \citeonline{Riffe1998}. O fator em comum nesses trabalhos foi a tentativa de descrever o significado destes segmentos utilizando técnicas computacionais e/ou conceitos de alto nível. Entretanto, trabalhos mais recentes relatam que cenas em noticiários tanto é um conjunto de tomadas que retratam uma simples ação acontecendo em um mesmo local, quanto uma montagem que retrata um único conceito, tema ou idéia sem limitações de tempo e espaço \cite{Choi2010}.

Por consequência dessas definições, o conceito de cena empregado neste trabalho segue a mesma linha de \citeonline{Choi2010} a qual representa um único tema ou idéia sem limitações de tempo ou espaço. Assim, cada notícia, vinheta ou comercial é uma cena diferente, pois entre o término de cada um destes segmentos e início do próximo ocorre uma mudança de tema/assunto, possivelmente alterando a correlação semântica e, portanto, ocasionando uma transição de cenas. Desse modo, considerando a estrutura dos telejornais (Figura \ref{fig:estruturatelejornal}) neste trabalho as transições de cenas acontecem quando ocorre:

\begin{itemize}
\item transição de notícias,
\item transição de vinheta para notícia (ou vice-versa) ou
\item transição de vinheta para comercial (ou vice-versa). 
\end{itemize}

\begin{figure}[h!]
\centering
\fbox{\includegraphics[scale=0.60]{./img/estruturatelejornal2.jpg}}
\caption{Composição temporal dos telejornais}
\label{fig:estruturatelejornal}
\end{figure}

De acordo com \citeonline{Chaisorn2003}, a maioria dos telejornais possuem uma estrutura similar e bem definida, a qual geralmente começa com uma abertura composta de resumos das principais notícias abordadas. A principal parte do programa contém uma série de histórias organizadas por interesse geográfico (nacional ou internacional) e várias categorias como política, interesses sociais, finanças, esportes e entretenimento. Cada história pode ser vista como uma notícia que normalmente começa com a imagem do repórter âncora, sendo que ao longo do programa ocorrem períodos de vinhetas e comerciais publicitários entre blocos de notícias. Mesmo que a ordem das cenas seja um pouco diferente de acordo com a transmissora/canal assistido, todos eles tem estrutura e categoria de notícias similares. Desse modo, a Figura \ref{fig:estruturatelejornal} apresenta a composição/estruturas do telejornal em relação ao tempo, assim como os possíveis casos em que ocorre a transição de cenas (representadas por linhas tracejadas em vermelho na vertical). O detalhe nessa figura ocorre por conta do bloco transparente de âncoras na segunda linha de cima para baixo, pois representa as notícias em quem não ocorrem as imagens dos âncoras, somente a fala desse apresentador, transição também considerada no escopo deste trabalho.

No contexto relacionado à notícia, ocorre somente uma peculiaridade e acontece quando, por exemplo, há notícias consecutivas e derivadas de uma mesma categoria (economia, esporte, etc), pois podem ocasionar dificuldades em identificar seus respectivos inícios e o términos. Para exemplificar o conceito, imagina-se um cenário em que o âncora apresenta (em forma de gráficos) um aumento da inflação na economia brasileira. Na sequência, outro âncora aborda o tema da consequência da inflação para o consumidor, aparecendo imagens de um supermercado e no áudio de fundo um repórter relatando a alta de preços de determinados produtos. E, por último, o mesmo âncora apresenta um pequeno trecho de entrevista do Ministro da Fazenda explicando a causa da inflação. Mesmo que o tema seja economia e o contexto do cenário (idéia) esteja relacionado à inflação brasileira, a definição adotada neste trabalho considera que esse cenário é composto por três notícias, exatamente porque o assunto em questão (inflação) retrata ações distintas (gráfico estatístico, impacto no dia-a-dia do consumidor e a explicação de uma autoridade do Poder Executivo) e não possuem as suas respectivas sequências de tomadas em um mesmo local. 

Uma observação importante está na abertura do telejornal e sua apresentação sucinta das notícias a serem abordadas posteriormente. Mesmo que a apresentação da notícia dure poucos segundos, esta é cumputada, obviamente, como cenas pelas mesmas razões citadas anteriormente. Outra observação está relacionada às vinhetas, pois elas atuam na separação de blocos do programa e podem ocorrer em três momentos: \textit{i)} no início do programa, após a abertura do telejornal; \textit{ii)} durante o programa como chamada para as próximas notícias (anteriormente ao intervalo comercial/propaganda publicitária); \textit{iii)} ao final, quando são apresentados os créditos da edição, como o editor, núcleo de redação, chefe de produção, diretor de imagem, etc. No término, não há notícias, no entanto, como o âncora apresenta o final da edição do telejornal, considera-se que o fim do telejornal é uma cena. Os comerciais também fazem parte do telejornal e são caracterizados pela vinheta do fim de um bloco de notícias e início do próximo bloco. Logo, as notícias, vinhetas e comercias são os três segmentos que compõem o gênero telejornal.

\section{Métodos de Segmentação de Vídeo}

Como apresentado na seção 2.3, a segmentação de vídeo temporal envolve a detecção de segmentos com menor duração de tempo e características semelhantes. Nesse contexto, esta seção descreve os principais métodos utilizados na literatura para a segmentação de vídeo, os quais são também utilizados neste trabalho.

\subsection{Histogramas de Cor}

O histograma de cor de uma imagem é uma característica visual construída contando o número de pixels de cada cor, ou seja, um histograma de imagem é referente à densidade de probabilidade da intensidade da imagem. De acordo com \citeonline{Zachary2001} essa descrição é importante e nos permite usar métodos da teoria da informação para expandir a representação de imagens com base em seu conteúdo. Com isso, uma imagem discreta $I=F(N_{1},N_{2})$ de tamanho $N_{1} \times N_{2}$ pode ser representada estatisticamente pela função de densidade de probabilidade:

\begin{eqnarray}
p(i) \equiv  p\{F(1,1), F(1,2),..., F(N_{1}, N_{2})\}
\label{for:}
\end{eqnarray} 

Considerando que cada valor do pixel é independente estatisticamente de todos os outros valores dos pixels, então a função de densidade de probabilidade é fatorada como: 

\begin{eqnarray}
p(i) = p\{ F(1,1)\} p\{ F(1,2) \} \dots p\{ F(N_{1}, N_{2})\}
\end{eqnarray} 

Para um conjunto discreto de valores, a interpretação de $p\{ F(i,j) \}$ é desenvolvida na base de intervalo finito de possíveis valores para $F(i,j)$. Em uma imagem digital, estes valores são as possíveis cores de cada pixel, geralmente assumindo que a distribuição de cores de uma imagem segue uma distribuição uniforme, ou seja, cada cor tem probabilidade $1/M$ de ser atribuída a um pixel, onde $M$ é a quantidade máxima de cores. 

Cogitando a função de densidade de probabilidade fatorada, \citeonline{Yinzi2010} definiu o histograma de cor como:
\begin{eqnarray}
h_{A,B,C}(a,b,c) = N \cdot Prob (A=a, B=b, C=c)
\label{eq:histograma}
\end{eqnarray}

\noindent onde $A$, $B$ e $C$ são as três dimensões de cores (RGB, HSV,...), $N$ é quantidade de pixels da imagem e $Prob$ é a probabilidade do pixel ter um valor de cor ($a, b, c$).

A medida de similaridade escolhida para comparar os histogramas de cor das imagens do trabalho desenvolvido foi a Intersecção de Histogramas. Essa proposta foi apresentada por \citeonline{Swain1991} na indexação de cor com aplicação em reconhecimento de objetos. De acordo com \citeonline{Barla2003} esse método mede o grau de similaridade entre dois histogramas de cor, sendo adequado para processamento de imagens não escaláveis e na presença de objetos não segmentados, possibilitando a construção de eficazes sistemas baseados em cor. 

A seguir são descritas as duas técnicas de histogramas de cor baseado na intersecção de histogramas como medida de similaridade.

\paragraph{Histograma Global de Cor}

O histograma global de cor considera a intensidade de cor de todos os pixels da imagem. O espaço de cor utilizado foi o RGB, quantizado em 256 bits para cada canal de cor. A fórmula da intersecção de histogramas globais de cor e suas especificidades são descritas a seguir \cite{Barla2003}:

\begin{eqnarray}
H_{(global)}(I,M)= \sum_{b=1}^{3}  \frac{\sum_{j=1}^{n} min(I_{j}, M_{j})} {\sum_{j=1}^{n} M_{j}}
\label{eq:histglobal}
\end{eqnarray}

\noindent onde \textit{n}=256, $I$ é o histograma de uma imagem modelo, no caso o âncora do telejornal, $M$ é o histograma de um quadro-chave de uma tomada e $b$ é o canal de cor no qual as duas imagens estão sendo comparadas ($b \in [R,G,B]$). O valor obtido da normalização fica no intervalo de 0 e 1. Portanto, quanto maior a similaridade entre as imagens, mais próximo o valor fica de 1.

\paragraph{Histograma Local de Cor}

O histograma local de cor, assim como o histograma global, calcula a intensidade das cores na imagem, entretanto, não considera os pixels em separados, mas sim um grupo deles, formando blocos ($B \times B$) de pixels.  Neste trabalho, o tamanho do bloco foi definido em $16 \times 16$ pixels. Portanto, o cálculo de intersecção de histograma calcula os histogramas de cada bloco da imagem modelo e os compara com o bloco equivalente da imagem candidata, descrito como \cite{Barla2003}:

\begin{eqnarray}
H_{(local)}(I,M)=\sum_{b=1}^{3}  \frac{\sum_{g=1}^{G} min(I_{g}, M_{g})} {\sum_{g=1}^{G} M_{g}}
\label{eq:histlocal}
\end{eqnarray}

\noindent onde G é a quantidade de de blocos da imagem ($G = [(N_{1} \times N_{2})/B]^2$), $I_{g}$ é o histograma local de cor no bloco $g$ da imagem modelo no canal de cor $b$ ($b \in [R,G,B]$), e $M_{g}$ é o histograma local de cor da imagem candidata. Do mesmo modo, o valor obtido da normalização também fica no intervalo de 0 e 1.

\subsection{Transformada Discreta de Wavelet}

As transformadas de wavelets, também chamada de decomposição wavelets, podem ser vistas como mecanismos para decompor ou quebrar sinais nas suas partes constituintes, permitindo analisar os dados em diferentes domínios de frequências com a resolução de cada componente amarrada à sua escala. Resumidamente, pode-se dizer que na análise wavelet, um sinal é decomposto nas funções derivadas da wavelet mãe em diversas escalas e deslocamentos temporais~\cite{Misiti1996}. Dentre as principais wavelets mãe destacam-se: a wavelet Haar, a família Deubechies, Coiflets, Symlets, Morlet e Meyer. 

Como a análise de Fourier, a representação wavelet fornece acesso a um conjunto de dados de vários níveis de detalhes, todavia, as wavelets diferenciam-se de Fourier no sentido que as diferentes frequências descritas pelas funções básicas da wavelet são locais ao invés de somente globais, como acontece com Fourier. Isso ocorre porquê essa técnica consegue distinguir as características locais de um sinal em diferentes escalas e, por translações, elas cobrem toda a região na qual o sinal é estudado. Por causa dessas propriedades únicas, as wavelets são usadas em análise numérica, reconhecimento de padrões, compressão de imagens e sons, computação gráfica, processamento de imagens, etc. Dentre as principais vantagens associadas ao uso de wavelets na área de processamento digital de imagens estão: as decomposições waveletes permitem uma boa aproximação da imagem original com poucos coeficientes; os coeficientes fornecem informação que é independente da resolução da imagem original, permitindo comparar facilmente imagens de resolução diferente; e decomposições rápidas e fáceis de computar, requerindo tempo linear no tamanho da imagem e pouco código~\cite{Wen1999}.

As transformadas wavelets podem ser contínuas ou discretas. A transformada wavelet contínua (do inglês, \textit{Continuous Wavelet Transform} - CWT), possui parâmetros de dilatação e translação que variam continuamente, ou seja, é aplicada a um sinal com resolução temporal infinita e, por conseguinte, precisa de infinitas escalas e deslocamentos temporais infinitamente suaves gerando assim infinitos coeficientes. A proposta da transformada wavelet discreta (do inglês, \textit{Discrete Wavelet Transform} - DWT) é escolher um subconjunto de parâmetros de dilatação e translação que variam discretamente, baseadas em potência de dois. Computacionalmente, a DWT tem melhor eficiência (mais rápida e economiza memória), exatamente por ser composta por valores discretizados do sinal. 

Portanto, na área de processamento digital de imagem é geralmente mais comum o uso da DWT para extrair características de textura e/ou reconhecimento de face, contudo, existem dois modos de decompor uma imagem bidimensional usando essa transformada: a decomposição padrão e a decomposição não-padrão. A decomposição padrão aplica a DWT unidimensional a cada linha de valores de pixels, resultando em um coeficiente de média e os coeficientes de detalhe para cada linha. Após, tratam-se estas linhas transformadas como se elas fossem uma imagem,  e aplica-se a DWT unidimensional para cada coluna. Os valores resultantes são todos os coeficientes de detalhes, exceto por um único coeficiente que representa a média geral. Na decomposição não-padrão são realizadas operações de decomposição alternadas entre linhas e colunas. Primeiro aplica-se o cálculo da média nos pares horizontais e faz-se a diferença dos valores dos pixels em cada linha da matriz que representa a imagem. Depois, aplica-se o cálculo da média nos pares verticais e encontra-se a diferença para a coluna do resultado. Por fim, repete-se o processo recursivamente apenas no quadrante contendo as médias em ambas as direções.

Outro modo de conseguir resultados mais eficazes é por intermédio da transformada wavelet rápida (do inglês, \textit{Fast Wavelet Transform} - FWT), utilizando os coeficientes da DWT \cite{Mallat1989}. Também conhecida como codificador de subfaixa de canais, a FWT envolve a filtragem do sinal de entrada baseada na função wavelet mãe utilizada.  

Começando com um sinal de entrada discreto, o primeiro estágio do algoritmo da FWT decompõe o sinal em dois conjuntos de coeficientes. Estes dois conjuntos são os coeficientes de aproximação, contendo informações de baixa frequência e os coeficientes de detalhes, contendo informações de alta frequência. O vetor dos coeficientes de aproximação é obtido através da convolução com o filtro passa-baixa e o vetor dos coeficientes de detalhes é obtido através da convolução com o filtro passa-alta. A operação de filtragem é seguida por uma dizimação diádica ou subamostragem por um fator 2, isto porque, após serem feitas as convoluções, o número de coeficientes é dobrado em relação ao sinal de entrada. Assim, o que operador de dizimação faz é eliminar todas as amostras de ordem ímpar dos vetores de aproximação e convolução, mantendo um número de coeficientes igual ao do vetor original.

Foi escolhido para este trabalho o uso da wavelet mais simples de Daubechies (daub4), gerada a partir de quatro coeficientes \cite{Nievergelt1999}:

%formula
\begin{eqnarray}
(h_{0},h_{1},h_{2},h_{3}) = \left( \frac{1+\sqrt{3} }{4\sqrt{2}}, \frac{3+\sqrt{3} }{4\sqrt{2}}, \frac{3-\sqrt{3} }{4\sqrt{2}}, \frac{1-\sqrt{3} }{4\sqrt{2}} \right)
\end{eqnarray}

A partir desses coeficientes constrõe-se a função escala:

%formula
\begin{eqnarray}
\phi(t)= \sqrt{2} \sum_{k=0}^{2N-1} h_{k} \phi(2t-k)
\end{eqnarray}

calcula-se $g_{n}$:

%formula
\begin{eqnarray}
(g_{0},g_{1},g_{2},g_{3}) = \left( \frac{1-\sqrt{3} }{4\sqrt{2}}, \frac{-3+\sqrt{3} }{4\sqrt{2}}, \frac{3+\sqrt{3} }{4\sqrt{2}}, \frac{-1-\sqrt{3} }{4\sqrt{2}} \right)
\end{eqnarray}

Asssim, a wavelet de Daubechies é dada por:

%formula
\begin{eqnarray}
\Psi(t)= \sqrt{2} \sum_{k=0}^{2N-1} g_{k} \phi(2t-k)
\label{eq:wavelet}
\end{eqnarray}

\noindent onde $N$ é a quantidade de coeficientes (4), $\phi$ é a função escala e $t$ é o tempo. Neste trabalho, a wavelet de Daubechies foi calculada com o auxílio da biblioteca JWave\footnote{http://code.google.com/p/jwave/} em Java.

A distância euclidiana foi a função de distância escolhida para medir a similaridade dos resultados das wavelets. Adotou-se essa função devido aos bons resultados obtidos durante a experimentação e, também, porque a literatura reporta experiências que sugerem sua boa adequação em aplicações de recuperação de informações \cite{Zhang2003}.  
	
O cálculo para a distância euclidiana é dado pela seguinte fórmula:	

\begin{eqnarray}
D_{euclidiana}(I,M)= \sum_{b=1}^3 \sqrt{(Dwt_{I} - Dwt_{M})^2}
\label{eq:dist_euclidiana}
\end{eqnarray}

\noindent onde $Dwt_{M}$ é a transformada discreta de wavelet rápida aplicada na imagem modelo, $Dwt_{I}$ é a transformada discreta de wavelet rápida aplicada na imagem que representa um quadro-chave do vídeo e $b$ é o canal de cor na qual as imagens estão sendo comparadas ($b \in [R, G, B]$).

\subsection{\textit{Root Mean Square}}

A maioria da características em nível de quadros de áudio são herdadas do tradicional processamento de áudio de voz/fala. Geralmente elas podem ser separadas em duas categorias: características no domínio do tempo, as quais são computadas diretamente das formas de onda, e da categoria de características no domínio da frequência, que são derivadas da transformada de Fourier das amostras nos quadros~\cite{Wang2000}. 
 
O volume, também referido como barulho/ruído/sonoridade (do inglês, \textit{loudness}\footnote{Esse termo causa subjetividade, uma vez que é uma medida que depende da frequência da resposta do ouvido humano. Portanto, é mais correto utilizar o termo volume, tanto em inglês quanto em português.}), é a característica mais utilizada e com pouca complexidade computacional. Para exemplificar, o estudo de~\citeonline{Liu1998b} descrevem uma técnica que extrai oito características de áudio, dentre elas o volume (com RMS), para classificação de programas de TV, que incluem jogos de futebol e basquete, comerciais, telejornais, etc. Ou ainda, \citeonline{Chen2003} criam técnicas, dentre elas uma taxa de silêncio por intermédio do volume (com RMS), para extrair cenas de ação e cenas com diálogos.

Visto como um indicador confiável de detecção de silêncio, o volume pode servir como um auxílio na segmentação de uma sequência de áudio e, normalmente, é aproximado pelo RMS da magnitude do sinal contido em cada quadro~\cite{Wang2000}. Especificamente, a raiz da média dos quadrados (do inglês, \textit{Root Mean Square}-RMS) revela a variação temporal da magnitude de um sinal em relação à distribuição do volume nos clipes de áudio.  O cálculo é feito, como o próprio nome diz, por um conjunto de quadros do som e computando a raiz quadrada da soma dos quadrados dos valores das amostras desses quadros, representado por:

\begin{eqnarray}
v(n)= \sqrt{\frac{1}{N} \sum_{i=0}^{N-1} s_{n}^2 (i)}
\end{eqnarray}

\noindent onde $N$ denota o tamanho do quadro, $s_{i}$ denota a $i$-ésima amostra no $n$-ésimo quadro, com $i$ e $n \in \mathbbm{N}$. 


\section{Avaliação de Resultados}

O modo de avaliação dos resultados na segmentação temporal do vídeo, tanto na detecção de cena quanto na detecção de tomadas, frequentemente ocorre por meio de medidas de avaliação quantitativas, denominadas Precisão (do inglês, \textit{Precision}) e Revocação (do inglês, \textit{Recall}). Não somente encontradas na segmentação de vídeo, essas medidas são comumente utilizadas na avaliação de desempenho dos algoritmos de recuperação de informação \cite{Modern1999}. O intuito de tal método é verificar a eficiência com base nos segmentos detectados de maneira correta (Fórmula \ref{eq:precis} - Precisão) e também avaliando casos em que detectou-se transições onde não ocorreram (Fórmula \ref{eq:rec} - Revocação ). As medidas são descritas a seguir: 

\begin{equation}
\textit{precisão} = \frac{num. \ verdadeiro \ positivos}{num. \ verdadeiro \ positivos \ + \ num. \ falso \ positivos}
\label{eq:precis}
\end{equation}

\begin{equation}
\textit{revocação} = \frac{num. \ verdadeiro \ positivos}{num. \ verdadeiro \ positivos \ + \ num. \ falso \ negativos}
\label{eq:rec}, onde
\end{equation}
\\

 \textsf{num.verdadeiro positivos} é a quantidade de segmentos corretos que foram detectadas pela técnica; \textsf{num. falso positivo} é a quantidade de segmentos que foram detectadas mas que não são corretos, ou seja, não existe e \textsf{num. falso negativo} é a quantidade de segmentos que não foram detectados mas que existem. 

Apesar dessa avaliação ser encontrada quase que na totalidade dos trabalhos de segmentação, algumas limitações são identificadas. \citeonline{Modern1999} relatam que uma estimativa apropriada para a revocação requer um conhecimento detalhado de todos os documentos envolvidos da amostra, principalmente se o conjunto da amostra for muito grande. O fato das duas medidas capturarem diferentes aspectos do conjunto de do\-cu\-men\-tos analisados pode ser interpretado como outro problema, possivelmente resolvido com uma abordagem que combine essas duas medidas (e.g. O significado Harmônico\footnote{Composta por uma função que obtém como resultado um valor entre 0 e 1. Sendo 0 quando não houve sucesso na recuperação de informação ou 1 quando ocorreu sucesso.} e a Medida E\footnote{Por meio de uma constante adicionada à formula, o usuário pode definir qual das duas medidas é mais importante, funcionando como um peso.}).

\citeonline{Zutschi2005} também descreve algumas limitações sobre o uso dessa avaliação ao relatar que a utilidade prática dessas medidas estão sendo questionadas sob o ponto de vista do usuário final. Notadamente, a medida de precisão não é um bom indicador para representar a percepção do usuário na qualidade em sistemas de recuperação de imagens baseada em conteúdo. Corroborando as palavras de Baeza-Yates \& Ribeiro-Neto, a revocação nem sequer fez parte da avaliação por não envolver reconhecimento avançado do conteúdo da base de dados de imagens. Outra questão envolvendo a recuperação multimídia baseado em conteúdo diz respeito à natureza da relevância dos dados. Os algoritmos tendem a agrupar dados similares, no entanto, o conceito de similaridade é subjetivo. O significado, ou semântica, de um dado depende do ponto de vista de cada usuário, assim faz-se necessário explicitar melhor semântica das informações para o usuário, a fim do sistema retornar resultados mais eficientes.  

Uma boa alternativa para substituir ou complementar a abordagem da precisão e revocação está em adotar medidas de avaliações centradas no usuário. Tais medidas fazem uso do usuário nos processos de classificação dos dados e avaliação dos resultados, possibilitando resultados mais eficientes, podendo conter um índice de significado semântico maior \cite{Zutschi2005}. 

%\section{Compressão de Vídeo Digital}
%\label{codificacao_de_video_digital}

%Como discutido, a organização eficiente dos dados de um vídeo digital permanece como uma questão em aberto, principalmente se provêm de inúmeras origens. Consequentemente, a consistência dos dados deve ser efetuada de maneira apropriada no sentido de armazenar em um formato padrão a fim de auxiliar o acesso e recuperação. Em um contexto onde há uma grande quantidade de vídeo, ou seja, um grande volume de dados, a redução do espaço de armazenamento torna-se desejável, necessitando a criação de um formato de compressão.  

%%Como discutido, a organização eficiente dos dados de um vídeo digital permanece como uma questão em aberto, principalmente se provêm de inúmeras origens. Consequentemente, a consistência dos dados deve ser efetuada de forma apropriada no sentido de armazenar em um formato padrão a fim de auxiliar o acesso e recuperação. Em um contexto onde há uma grande quantidade de vídeo, ou seja, um grande volume de dados, a redução do espaço de armazenamento torna-se desejável, necessitando a criação de um formato de compressão.  

%Foi com o intuito inicial de comprimir o espaço de dados digitais e, posteriormente, promover a interoperabilidade entre diversas aplicações multimídia, que o grupo MPEG (\textit{The Moving Picture Coding Experts Group} - Grupo de Especialistas de Codificação de Imagens em Movimento) criou, em 1988, uma família de padrões (MPEG-1, MPEG-2, MPEG-4, MPEG-7 e MPEG-21). Como um grupo desenvolvido pela ISO (\textit{International Organisation for Standardisation} - Organização Internacional de Padrões), este tem como finalidade desenvolver padrões internacionais de compressão, descompressão, processamento, codificação e representação de imagens em movimento, áudio e suas combinações, com o intuito de satisfazer a maior variedade de aplicações~\cite{Wu2001}.

%Dentre as práticas mais adotadas no processo de análise do vídeo está o uso desses padrões de compressão. MPEG-1, MPEG-2 e MPEG-4 são os padrões com algoritmos de compressão do grupo MPEG. Já o padrão H.26x pertence ao Grupo de Peritos em Codificação de Vídeos (Video Coding Experts Group-VCEG) e possui o H.264 como o mais recente padrão de codificação aprovado em conjunto com os grupos MPEG e VCEG, sendo utilizado em vídeos criados por usuários e vídeos de conferência, aproveitando sua baixa taxa de \textit{bits}~\cite{Tang2009}. Autores adotam esses padrões para facilitar a extração de informação em conteúdo multimídia. Benefícios como redução da complexidade computacional, tempo de processamento e quantidade de memória utilizada são mencionados como fatores que levam a adoção dessa abordagem~\cite{Ngo1998, Ngo2001, Calic2002}.

%Algoritmos que seguem este padrão empregam uma combinação de técnicas de compressão com perda juntamente com compressão sem perda no processo de codificação de vídeo. Ambas as compressões são divididas em três etapas, sendo a etapa de compressão com perda composta pelas etapas de Estimativa de Movimento, Codificação por DCT e Quantização, e as etapas sem perdas composta por Vetorização, Codificação por Entropia e \textit{BitsTream}. Todos os estágios de compressão trazem como vantagem a obtenção de um arquivo comprimido de menor dimensão, mantendo, no entanto, uma qualidade mínima em relação ao original, conforme o objetivo que se pretende. 

%Reduções temporais e espaciais compõem as técnicas de compressão de dados do padrão. Na compressão temporal utilizam-se diferentes modos de compressão dos dados para possibilitar a geração do fluxo elementar do vídeo \cite{MPEG22000}. Já na compressão espacial são eliminadas informações redundantes buscando identificar as informações repetidas presentes em quadros próximos para codificar apenas um desses quadros, eliminando a codificação da informação nos demais, diminuindo a quantidade de informação a ser codificada no \textit{Bitstream} final \cite{richard2002}.     

%%Autores que adotam esse padrão visam formas mais fáceis de extrair informação do conteúdo do vídeo. Benefícios como ...., ... , ... são mencionados como fatores que levam a adoção dessa abordagem. Os autores optam por determinada padrão dependendo da metodologia e do objetivo abordado, entretanto, geralmente os formatos MPEG-1, MPEG-2 e MPEG-4 são utilizados para extrair informações devido aos benefícios inclusos em suas codificações,

%%Como o vídeo é a matéria-prima desse estudo, as técnicas ou algoritmos utilizados para facilitar sua manipulação frequentemente fazem uso desses tipos de padrões. Os autores optam por determinada padrão dependendo da metodologia e do objetivo abordado, entretanto, geralmente os formatos MPEG-1, MPEG-2 e MPEG-4 são utilizados para extrair informações devido aos benefícios inclusos em suas codificações, o MPEG-7 é utilizado para descrever conteúdo, ou seja, descrever essas informações e o MPEG-21 é um padrão recente utilizado para descrever um ambiente de uso multimídia~\cite{magalhaes2004}. Por tratar-se de um padrão muito recente, poucos são os trabalhos relevantes que bordam o padrão MPEG-21 no contexto de recuperação de informação em vídeo, portanto com exceção desse, os demais padrões estão descritos, resumidamente, a seguir.

%\subsection{MPEG-1}
%\label{mpeg_1}

%O padrão de codificação MPEG-1 foi desenvolvido, em 1992, para ser genérico, padronizando uma versão codificada de vídeo e áudio, tendo em vista o suporte a diferentes tipos de aplicações, desde sistemas interativos em CD-ROM (do inglês, \textit{Compact Disc - Read Only Memory}) à serviço de entrega de vídeos sobre redes de telecomunicação~\cite{Sikora1997}. Basicamente, o seu maior uso foi como padrão para armazenamento e recuperação eficiente de áudio e vídeo em discos compactados (do inglês, \textit{Compact Disc - CD}), possuindo uma taxa de bits de 1.5 Mbit/s~\cite{MPEG11996}.

%Essa codificação é dividida em 5 partes, onde cada uma delas aborda diferentes aspectos da especificação, incluindo desde a codificação de vídeo e áudio, até meios de se multiplexar os dados e verificar a taxa de bits do codificador e do decodificador. Embora o seu maior uso foi como padrão para armazenamento e recuperação eficiente de áudio e vídeo em discos compactados (do inglês, \textit{Compact Disc}), possuindo uma taxa de bits de 1.5 Mbit/s, este formato fornece em sua especificação de vídeo uma resolução equivalente ao VHS (do inglês, \textit{Video Home System - Sistema de Vídeo Caseiro}) e qualidade de áudio equivalente ao CD, tendo o MP3 implementado em sua terceira camada de áudio. 

%Outras características importantes fornecidas pelo MPEG-1 incluem o acesso randômico baseado em quadros, operações de busca \textit{fast forward/fast reverse (FF/FV)} por meio de fluxo de bits comprimidos, reprodução reversa de vídeo e edição de fluxo de bits comprimidos~\cite{Sikora1997}.

%\subsection{MPEG-2}
%\label{mpeg_2}

%Em 1996 o Grupo MPEG cria outro padrão de codificação devido ao sucesso comercial do MPEG-1 e, assim, como o anterior, sua especificação também tende a ser genérica, visando a facilidade nas trocas de bits entre diferentes aplicações, transmissão e armazenamento de mídia. Em razão de sua finalidade ser transmitir vídeo digital de alta qualidade, aplicações emergentes como a distribuição à cabo da TV digital, satélites e propagação do sinal digital podem ser vistas como benefícios da nova criação de uma codificação~\cite{Sikora1997}. 

%Por manter compatibilidade retroativa com MPEG-1, o MPEG-2 possui uma taxa de bits que varia de 1.5 Mbit/s (qualidade de VHS), até 140 Mbits/s, que são utilizadas em aplicações que envolvem TV digital e HDTV (do inglês, \textit{High Definition TeleVision - Televisão de Alta Definição}). Outros aspectos importantes é a descrição de aspectos necessários para multiplexação de dados, sincronização, vídeo entrelaçado em tela cheia e \textit{links} lógicos de rede~\cite{FAIRHURST2001}. 

%A divisão da especificação ocorre em dez partes~\cite{MPEG22000}. Merecem maior destaque é a sexta parte que descreve a rede DSM-CC (do inglês, \textit{Digital Store Media Command and Control - Comando e Controle de Mídia e Armazenamento Digital}), constituído de um conjunto de protocolos que oferecem funções específicas de controle e operação para gerenciar o fluxo de bits codificados; e também a nona parte, a RTI (do inglês, \textit{Real Time Interface for System Decoders} - Interface para Sistemas de Codificação em Tempo Real), que descreve uma interface para decodificadores em tempo real para adaptar todos os tipos de rede apropriados carregando pacotes TS (\textit{Transport Streams - Fluxos de Transporte}).   

%\subsection{MPEG-4}
%\label{mpeg_4}

%A especificação do MPEG-4 foi criada em 1998 e tem como meta definir um padrão internacional de codificação audiovisual que atenda às necessidades emergentes dos serviços de interação, comunicação e difusão, assim como às necessidades de serviços mistos resultantes da convergência dos mesmos~\cite{GOULARTE2003}. Ainda que o MPEG-1 e o MPEG-2 tenha sido a base para a construção desse padrão, a codificação e transmissão não mais ocorre de forma linear, sendo substituído pela divisão do vídeo em objetos de mídia, os quais são codificados e transmitidos separadamente para o destino~\cite{MPEG42002}.

%Os objetos de mídia são os componentes que fazem o diferencial no padrão. Esses possuem propriedades definidas por uma linguagem de descrição de cena e podem ser categorizados de acordo com o tipo, naturais ou sintéticos, ou de forma hierárquica, imagens estáticas, objetos visuais ou objetos de áudio. Objetos naturais são aqueles capturados a partir de câmeras e microfones e os objetos sintéticos são gerados por computador, como texto, gráficos em duas dimensões ou três (2D e 3D), animações e música computacional~\cite{GOULARTE2003}. De forma hierárquica, imagens estáticas são representadas como planos de fundo; os objetos visuais por uma conversa (sem o plano de fundo) e os objetos de áudio como uma música de fundo ou a voz de uma pessoa~\cite{MPEG42002}. Combinações entre qualquer elemento citado podem formar cenas complexas, com um alto poder de manipulação de dados.    

%As funcionalidades e características mais importantes desse padrão podem ser agrupadas em três categorias~\cite{Pereira2002}:
%\begin{itemize}
%\item Compressão eficiente: a codificação eficiente auxilia a transmissão de dados audiovisuais em redes com pouca largura de banda e armazenamento em dispositivos móveis. Ocorre também a melhoria na codificação de múltiplos fluxos de dados concorrentes, permitindo a codificação de visões e trilhas sonoras de uma mesa cena.  
%\item Interatividade baseada em conteúdo: uma das mais importantes e inovadora contribuição foi a codificação e representação de objetos de vídeo ao invés de quadros de vídeo permitem aplicações baseada em conteúdo, as quais possuem acesso e organização de dados audiovisuais através de ferramentas para indexação, busca, navegação, carga, descarga e deleção. 
%\item Acesso Universal: a robustez em ambientes propensos a erros permite o MPEG-4 codificar conteúdo para tornar acessível diferentes tipos de redes, tanto móveis (sem fio) quanto com fio. Ainda, a escalabilidade de resoluções temporais ou espaciais permitem ao usuário decidir onde irá alocar recursos como largura de banda, capacidade computacional ou consumo de energia.
%\end{itemize} 

%O padrão MPEG-4 defini também a biblioteca MPEG-J para combinar programas que realizam reprodução de vídeo (\textit{players}) com código Java. Relacionando esse padrão com um código seguro, criadores podem embutir controles complexos e mecanismos de processamento de dados com seus dados de mídia para gerenciar a operação da sessão audiovisual~\cite{MPEG42002}.

%\subsection{MPEG-7}
%\label{mpeg_7}

%MPEG-7 é um padrão para descrição de dados do conteúdo multimídia que suporta algum nível de interpretação do significado da informação, o qual pode ser transmitido ou acessado por um computador ou código computacional~\cite{MPEG72004}. Por meio de sua especificação um conjunto de descritores (do inglês, \textit{Descriptors}) podem ser usados para representar vários tipos de informações multimídia, tais como: imagens estáticas, gráficos, modelos 3D, áudio, fala, vídeo, etc. Além dos descritores, fazem parte desse padrão os esquemas de descrição (do inglês, \textit{Description Schemes} - DSs) e a linguagem de definição de descrição (do inglês, \textit{Description Definition Language} - DDL). Enquanto os esquemas de descrição especificam estruturas pré-definidas de descritores, seus relacionamentos e formas do usuário definir suas próprias estruturas, a linguagem de definição fornece a definição de um descritor ou esquema de descrição.

%O uso dos padrões MPEG-4 e MPEG-7 não são exclusivos, ou seja, podem coexistir numa mesma aplicação. Como exemplo, os descritores MPEG-7 podem explorar as vantagens fornecidas pelo MPEG-4 compondo descrições das características de seus objetos. Tais características incluem informações de índice (título, autor, etc.) e informações sobre o significado semântico do objeto (quantas e quais pessoas aparecem na cena, qual o local, o que está acontecendo,etc.)~\cite{GOULARTE2003}.

%Soluções para documentos de tipo somente texto, desenvolvimento de algoritmos e ferramentas para extração automática ou semi-automática de características e desenvolver ferramentas de busca não fazem parte da especificação do padrão MPEG-7~\cite{MPEG72004}. Embora a forma como os dados MPEG-7 são utilizados nas perguntas do usuário não fazer parte de seu objetivo, em princípio, qualquer tipo de conteúdo multimídia pode ser recuperado por meio de qualquer tipo de material de busca, sendo responsabilidade do mecanismo de busca associar os dados da pesquisa à descrição MPEG-7 do conteúdo multimídia~\cite{MPEG72004, Chang2001}.  

\section{Considerações Finais}

Este capítulo apresentou os conceitos e tecnologias relacionadas ao processo de análise de conteúdo de vídeo digital. A estrutura do vídeo, assim como seus segmentos, também foram descritos de modo que fique mais fácil a leitura dos temas relacionado a essa área e que serão abordados nos próximos capítulos.   

Observou-se que a recuperação e manipulação de informação em conteúdo multimídia não é uma tarefa simples. É necessário realizar a extração de dados como cor, textura, movimentação, etc, para segmentar o vídeo em pedaços menores a fim de facilitar seu acesso posterior. Segmentar o conteúdo em cenas, ou unidades semânticas, para identificar conteúdo de alto nível é ainda mais difícil, visto que há uma lacuna entre os dados do vídeo e a interpretação do usuário, além de existir várias categorias semânticas de vídeos. 

Definições mais específicas para o gênero telejornais foram apresentadas com o intuito de exemplificar e explicar os conceitos deste trabalho, assim como também ocorre com os métodos de segmentação de vídeo. Para avaliação de técnicas que realizam segmentação semântica em vídeos, frequentemente são utilizadas medidas qualitativas como a precisão e a revocação, as quais tem o intuito de verificar a eficiência da metodologia empregada.